Fold number 1
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_1 (InputLayer)             (None, 299, 299, 3)   0                                            
____________________________________________________________________________________________________
conv2d_1 (Conv2D)                (None, 149, 149, 32)  864         input_1[0][0]                    
____________________________________________________________________________________________________
batch_normalization_1 (BatchNorm (None, 149, 149, 32)  96          conv2d_1[0][0]                   
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 149, 149, 32)  0           batch_normalization_1[0][0]      
____________________________________________________________________________________________________
conv2d_2 (Conv2D)                (None, 147, 147, 32)  9216        activation_1[0][0]               
____________________________________________________________________________________________________
batch_normalization_2 (BatchNorm (None, 147, 147, 32)  96          conv2d_2[0][0]                   
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 147, 147, 32)  0           batch_normalization_2[0][0]      
____________________________________________________________________________________________________
conv2d_3 (Conv2D)                (None, 147, 147, 64)  18432       activation_2[0][0]               
____________________________________________________________________________________________________
batch_normalization_3 (BatchNorm (None, 147, 147, 64)  192         conv2d_3[0][0]                   
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 147, 147, 64)  0           batch_normalization_3[0][0]      
____________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)   (None, 73, 73, 64)    0           activation_3[0][0]               
____________________________________________________________________________________________________
conv2d_4 (Conv2D)                (None, 73, 73, 80)    5120        max_pooling2d_1[0][0]            
____________________________________________________________________________________________________
batch_normalization_4 (BatchNorm (None, 73, 73, 80)    240         conv2d_4[0][0]                   
____________________________________________________________________________________________________
activation_4 (Activation)        (None, 73, 73, 80)    0           batch_normalization_4[0][0]      
____________________________________________________________________________________________________
conv2d_5 (Conv2D)                (None, 71, 71, 192)   138240      activation_4[0][0]               
____________________________________________________________________________________________________
batch_normalization_5 (BatchNorm (None, 71, 71, 192)   576         conv2d_5[0][0]                   
____________________________________________________________________________________________________
activation_5 (Activation)        (None, 71, 71, 192)   0           batch_normalization_5[0][0]      
____________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)   (None, 35, 35, 192)   0           activation_5[0][0]               
____________________________________________________________________________________________________
conv2d_9 (Conv2D)                (None, 35, 35, 64)    12288       max_pooling2d_2[0][0]            
____________________________________________________________________________________________________
batch_normalization_9 (BatchNorm (None, 35, 35, 64)    192         conv2d_9[0][0]                   
____________________________________________________________________________________________________
activation_9 (Activation)        (None, 35, 35, 64)    0           batch_normalization_9[0][0]      
____________________________________________________________________________________________________
conv2d_7 (Conv2D)                (None, 35, 35, 48)    9216        max_pooling2d_2[0][0]            
____________________________________________________________________________________________________
conv2d_10 (Conv2D)               (None, 35, 35, 96)    55296       activation_9[0][0]               
____________________________________________________________________________________________________
batch_normalization_7 (BatchNorm (None, 35, 35, 48)    144         conv2d_7[0][0]                   
____________________________________________________________________________________________________
batch_normalization_10 (BatchNor (None, 35, 35, 96)    288         conv2d_10[0][0]                  
____________________________________________________________________________________________________
activation_7 (Activation)        (None, 35, 35, 48)    0           batch_normalization_7[0][0]      
____________________________________________________________________________________________________
activation_10 (Activation)       (None, 35, 35, 96)    0           batch_normalization_10[0][0]     
____________________________________________________________________________________________________
average_pooling2d_1 (AveragePool (None, 35, 35, 192)   0           max_pooling2d_2[0][0]            
____________________________________________________________________________________________________
conv2d_6 (Conv2D)                (None, 35, 35, 64)    12288       max_pooling2d_2[0][0]            
____________________________________________________________________________________________________
conv2d_8 (Conv2D)                (None, 35, 35, 64)    76800       activation_7[0][0]               
____________________________________________________________________________________________________
conv2d_11 (Conv2D)               (None, 35, 35, 96)    82944       activation_10[0][0]              
____________________________________________________________________________________________________
conv2d_12 (Conv2D)               (None, 35, 35, 32)    6144        average_pooling2d_1[0][0]        
____________________________________________________________________________________________________
batch_normalization_6 (BatchNorm (None, 35, 35, 64)    192         conv2d_6[0][0]                   
____________________________________________________________________________________________________
batch_normalization_8 (BatchNorm (None, 35, 35, 64)    192         conv2d_8[0][0]                   
____________________________________________________________________________________________________
batch_normalization_11 (BatchNor (None, 35, 35, 96)    288         conv2d_11[0][0]                  
____________________________________________________________________________________________________
batch_normalization_12 (BatchNor (None, 35, 35, 32)    96          conv2d_12[0][0]                  
____________________________________________________________________________________________________
activation_6 (Activation)        (None, 35, 35, 64)    0           batch_normalization_6[0][0]      
____________________________________________________________________________________________________
activation_8 (Activation)        (None, 35, 35, 64)    0           batch_normalization_8[0][0]      
____________________________________________________________________________________________________
activation_11 (Activation)       (None, 35, 35, 96)    0           batch_normalization_11[0][0]     
____________________________________________________________________________________________________
activation_12 (Activation)       (None, 35, 35, 32)    0           batch_normalization_12[0][0]     
____________________________________________________________________________________________________
mixed0 (Concatenate)             (None, 35, 35, 256)   0           activation_6[0][0]               
                                                                   activation_8[0][0]               
                                                                   activation_11[0][0]              
                                                                   activation_12[0][0]              
____________________________________________________________________________________________________
conv2d_16 (Conv2D)               (None, 35, 35, 64)    16384       mixed0[0][0]                     
____________________________________________________________________________________________________
batch_normalization_16 (BatchNor (None, 35, 35, 64)    192         conv2d_16[0][0]                  
____________________________________________________________________________________________________
activation_16 (Activation)       (None, 35, 35, 64)    0           batch_normalization_16[0][0]     
____________________________________________________________________________________________________
conv2d_14 (Conv2D)               (None, 35, 35, 48)    12288       mixed0[0][0]                     
____________________________________________________________________________________________________
conv2d_17 (Conv2D)               (None, 35, 35, 96)    55296       activation_16[0][0]              
____________________________________________________________________________________________________
batch_normalization_14 (BatchNor (None, 35, 35, 48)    144         conv2d_14[0][0]                  
____________________________________________________________________________________________________
batch_normalization_17 (BatchNor (None, 35, 35, 96)    288         conv2d_17[0][0]                  
____________________________________________________________________________________________________
activation_14 (Activation)       (None, 35, 35, 48)    0           batch_normalization_14[0][0]     
____________________________________________________________________________________________________
activation_17 (Activation)       (None, 35, 35, 96)    0           batch_normalization_17[0][0]     
____________________________________________________________________________________________________
average_pooling2d_2 (AveragePool (None, 35, 35, 256)   0           mixed0[0][0]                     
____________________________________________________________________________________________________
conv2d_13 (Conv2D)               (None, 35, 35, 64)    16384       mixed0[0][0]                     
____________________________________________________________________________________________________
conv2d_15 (Conv2D)               (None, 35, 35, 64)    76800       activation_14[0][0]              
____________________________________________________________________________________________________
conv2d_18 (Conv2D)               (None, 35, 35, 96)    82944       activation_17[0][0]              
____________________________________________________________________________________________________
conv2d_19 (Conv2D)               (None, 35, 35, 64)    16384       average_pooling2d_2[0][0]        
____________________________________________________________________________________________________
batch_normalization_13 (BatchNor (None, 35, 35, 64)    192         conv2d_13[0][0]                  
____________________________________________________________________________________________________
batch_normalization_15 (BatchNor (None, 35, 35, 64)    192         conv2d_15[0][0]                  
____________________________________________________________________________________________________
batch_normalization_18 (BatchNor (None, 35, 35, 96)    288         conv2d_18[0][0]                  
____________________________________________________________________________________________________
batch_normalization_19 (BatchNor (None, 35, 35, 64)    192         conv2d_19[0][0]                  
____________________________________________________________________________________________________
activation_13 (Activation)       (None, 35, 35, 64)    0           batch_normalization_13[0][0]     
____________________________________________________________________________________________________
activation_15 (Activation)       (None, 35, 35, 64)    0           batch_normalization_15[0][0]     
____________________________________________________________________________________________________
activation_18 (Activation)       (None, 35, 35, 96)    0           batch_normalization_18[0][0]     
____________________________________________________________________________________________________
activation_19 (Activation)       (None, 35, 35, 64)    0           batch_normalization_19[0][0]     
____________________________________________________________________________________________________
mixed1 (Concatenate)             (None, 35, 35, 288)   0           activation_13[0][0]              
                                                                   activation_15[0][0]              
                                                                   activation_18[0][0]              
                                                                   activation_19[0][0]              
____________________________________________________________________________________________________
conv2d_23 (Conv2D)               (None, 35, 35, 64)    18432       mixed1[0][0]                     
____________________________________________________________________________________________________
batch_normalization_23 (BatchNor (None, 35, 35, 64)    192         conv2d_23[0][0]                  
____________________________________________________________________________________________________
activation_23 (Activation)       (None, 35, 35, 64)    0           batch_normalization_23[0][0]     
____________________________________________________________________________________________________
conv2d_21 (Conv2D)               (None, 35, 35, 48)    13824       mixed1[0][0]                     
____________________________________________________________________________________________________
conv2d_24 (Conv2D)               (None, 35, 35, 96)    55296       activation_23[0][0]              
____________________________________________________________________________________________________
batch_normalization_21 (BatchNor (None, 35, 35, 48)    144         conv2d_21[0][0]                  
____________________________________________________________________________________________________
batch_normalization_24 (BatchNor (None, 35, 35, 96)    288         conv2d_24[0][0]                  
____________________________________________________________________________________________________
activation_21 (Activation)       (None, 35, 35, 48)    0           batch_normalization_21[0][0]     
____________________________________________________________________________________________________
activation_24 (Activation)       (None, 35, 35, 96)    0           batch_normalization_24[0][0]     
____________________________________________________________________________________________________
average_pooling2d_3 (AveragePool (None, 35, 35, 288)   0           mixed1[0][0]                     
____________________________________________________________________________________________________
conv2d_20 (Conv2D)               (None, 35, 35, 64)    18432       mixed1[0][0]                     
____________________________________________________________________________________________________
conv2d_22 (Conv2D)               (None, 35, 35, 64)    76800       activation_21[0][0]              
____________________________________________________________________________________________________
conv2d_25 (Conv2D)               (None, 35, 35, 96)    82944       activation_24[0][0]              
____________________________________________________________________________________________________
conv2d_26 (Conv2D)               (None, 35, 35, 64)    18432       average_pooling2d_3[0][0]        
____________________________________________________________________________________________________
batch_normalization_20 (BatchNor (None, 35, 35, 64)    192         conv2d_20[0][0]                  
____________________________________________________________________________________________________
batch_normalization_22 (BatchNor (None, 35, 35, 64)    192         conv2d_22[0][0]                  
____________________________________________________________________________________________________
batch_normalization_25 (BatchNor (None, 35, 35, 96)    288         conv2d_25[0][0]                  
____________________________________________________________________________________________________
batch_normalization_26 (BatchNor (None, 35, 35, 64)    192         conv2d_26[0][0]                  
____________________________________________________________________________________________________
activation_20 (Activation)       (None, 35, 35, 64)    0           batch_normalization_20[0][0]     
____________________________________________________________________________________________________
activation_22 (Activation)       (None, 35, 35, 64)    0           batch_normalization_22[0][0]     
____________________________________________________________________________________________________
activation_25 (Activation)       (None, 35, 35, 96)    0           batch_normalization_25[0][0]     
____________________________________________________________________________________________________
activation_26 (Activation)       (None, 35, 35, 64)    0           batch_normalization_26[0][0]     
____________________________________________________________________________________________________
mixed2 (Concatenate)             (None, 35, 35, 288)   0           activation_20[0][0]              
                                                                   activation_22[0][0]              
                                                                   activation_25[0][0]              
                                                                   activation_26[0][0]              
____________________________________________________________________________________________________
conv2d_28 (Conv2D)               (None, 35, 35, 64)    18432       mixed2[0][0]                     
____________________________________________________________________________________________________
batch_normalization_28 (BatchNor (None, 35, 35, 64)    192         conv2d_28[0][0]                  
____________________________________________________________________________________________________
activation_28 (Activation)       (None, 35, 35, 64)    0           batch_normalization_28[0][0]     
____________________________________________________________________________________________________
conv2d_29 (Conv2D)               (None, 35, 35, 96)    55296       activation_28[0][0]              
____________________________________________________________________________________________________
batch_normalization_29 (BatchNor (None, 35, 35, 96)    288         conv2d_29[0][0]                  
____________________________________________________________________________________________________
activation_29 (Activation)       (None, 35, 35, 96)    0           batch_normalization_29[0][0]     
____________________________________________________________________________________________________
conv2d_27 (Conv2D)               (None, 17, 17, 384)   995328      mixed2[0][0]                     
____________________________________________________________________________________________________
conv2d_30 (Conv2D)               (None, 17, 17, 96)    82944       activation_29[0][0]              
____________________________________________________________________________________________________
batch_normalization_27 (BatchNor (None, 17, 17, 384)   1152        conv2d_27[0][0]                  
____________________________________________________________________________________________________
batch_normalization_30 (BatchNor (None, 17, 17, 96)    288         conv2d_30[0][0]                  
____________________________________________________________________________________________________
activation_27 (Activation)       (None, 17, 17, 384)   0           batch_normalization_27[0][0]     
____________________________________________________________________________________________________
activation_30 (Activation)       (None, 17, 17, 96)    0           batch_normalization_30[0][0]     
____________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)   (None, 17, 17, 288)   0           mixed2[0][0]                     
____________________________________________________________________________________________________
mixed3 (Concatenate)             (None, 17, 17, 768)   0           activation_27[0][0]              
                                                                   activation_30[0][0]              
                                                                   max_pooling2d_3[0][0]            
____________________________________________________________________________________________________
conv2d_35 (Conv2D)               (None, 17, 17, 128)   98304       mixed3[0][0]                     
____________________________________________________________________________________________________
batch_normalization_35 (BatchNor (None, 17, 17, 128)   384         conv2d_35[0][0]                  
____________________________________________________________________________________________________
activation_35 (Activation)       (None, 17, 17, 128)   0           batch_normalization_35[0][0]     
____________________________________________________________________________________________________
conv2d_36 (Conv2D)               (None, 17, 17, 128)   114688      activation_35[0][0]              
____________________________________________________________________________________________________
batch_normalization_36 (BatchNor (None, 17, 17, 128)   384         conv2d_36[0][0]                  
____________________________________________________________________________________________________
activation_36 (Activation)       (None, 17, 17, 128)   0           batch_normalization_36[0][0]     
____________________________________________________________________________________________________
conv2d_32 (Conv2D)               (None, 17, 17, 128)   98304       mixed3[0][0]                     
____________________________________________________________________________________________________
conv2d_37 (Conv2D)               (None, 17, 17, 128)   114688      activation_36[0][0]              
____________________________________________________________________________________________________
batch_normalization_32 (BatchNor (None, 17, 17, 128)   384         conv2d_32[0][0]                  
____________________________________________________________________________________________________
batch_normalization_37 (BatchNor (None, 17, 17, 128)   384         conv2d_37[0][0]                  
____________________________________________________________________________________________________
activation_32 (Activation)       (None, 17, 17, 128)   0           batch_normalization_32[0][0]     
____________________________________________________________________________________________________
activation_37 (Activation)       (None, 17, 17, 128)   0           batch_normalization_37[0][0]     
____________________________________________________________________________________________________
conv2d_33 (Conv2D)               (None, 17, 17, 128)   114688      activation_32[0][0]              
____________________________________________________________________________________________________
conv2d_38 (Conv2D)               (None, 17, 17, 128)   114688      activation_37[0][0]              
____________________________________________________________________________________________________
batch_normalization_33 (BatchNor (None, 17, 17, 128)   384         conv2d_33[0][0]                  
____________________________________________________________________________________________________
batch_normalization_38 (BatchNor (None, 17, 17, 128)   384         conv2d_38[0][0]                  
____________________________________________________________________________________________________
activation_33 (Activation)       (None, 17, 17, 128)   0           batch_normalization_33[0][0]     
____________________________________________________________________________________________________
activation_38 (Activation)       (None, 17, 17, 128)   0           batch_normalization_38[0][0]     
____________________________________________________________________________________________________
average_pooling2d_4 (AveragePool (None, 17, 17, 768)   0           mixed3[0][0]                     
____________________________________________________________________________________________________
conv2d_31 (Conv2D)               (None, 17, 17, 192)   147456      mixed3[0][0]                     
____________________________________________________________________________________________________
conv2d_34 (Conv2D)               (None, 17, 17, 192)   172032      activation_33[0][0]              
____________________________________________________________________________________________________
conv2d_39 (Conv2D)               (None, 17, 17, 192)   172032      activation_38[0][0]              
____________________________________________________________________________________________________
conv2d_40 (Conv2D)               (None, 17, 17, 192)   147456      average_pooling2d_4[0][0]        
____________________________________________________________________________________________________
batch_normalization_31 (BatchNor (None, 17, 17, 192)   576         conv2d_31[0][0]                  
____________________________________________________________________________________________________
batch_normalization_34 (BatchNor (None, 17, 17, 192)   576         conv2d_34[0][0]                  
____________________________________________________________________________________________________
batch_normalization_39 (BatchNor (None, 17, 17, 192)   576         conv2d_39[0][0]                  
____________________________________________________________________________________________________
batch_normalization_40 (BatchNor (None, 17, 17, 192)   576         conv2d_40[0][0]                  
____________________________________________________________________________________________________
activation_31 (Activation)       (None, 17, 17, 192)   0           batch_normalization_31[0][0]     
____________________________________________________________________________________________________
activation_34 (Activation)       (None, 17, 17, 192)   0           batch_normalization_34[0][0]     
____________________________________________________________________________________________________
activation_39 (Activation)       (None, 17, 17, 192)   0           batch_normalization_39[0][0]     
____________________________________________________________________________________________________
activation_40 (Activation)       (None, 17, 17, 192)   0           batch_normalization_40[0][0]     
____________________________________________________________________________________________________
mixed4 (Concatenate)             (None, 17, 17, 768)   0           activation_31[0][0]              
                                                                   activation_34[0][0]              
                                                                   activation_39[0][0]              
                                                                   activation_40[0][0]              
____________________________________________________________________________________________________
conv2d_45 (Conv2D)               (None, 17, 17, 160)   122880      mixed4[0][0]                     
____________________________________________________________________________________________________
batch_normalization_45 (BatchNor (None, 17, 17, 160)   480         conv2d_45[0][0]                  
____________________________________________________________________________________________________
activation_45 (Activation)       (None, 17, 17, 160)   0           batch_normalization_45[0][0]     
____________________________________________________________________________________________________
conv2d_46 (Conv2D)               (None, 17, 17, 160)   179200      activation_45[0][0]              
____________________________________________________________________________________________________
batch_normalization_46 (BatchNor (None, 17, 17, 160)   480         conv2d_46[0][0]                  
____________________________________________________________________________________________________
activation_46 (Activation)       (None, 17, 17, 160)   0           batch_normalization_46[0][0]     
____________________________________________________________________________________________________
conv2d_42 (Conv2D)               (None, 17, 17, 160)   122880      mixed4[0][0]                     
____________________________________________________________________________________________________
conv2d_47 (Conv2D)               (None, 17, 17, 160)   179200      activation_46[0][0]              
____________________________________________________________________________________________________
batch_normalization_42 (BatchNor (None, 17, 17, 160)   480         conv2d_42[0][0]                  
____________________________________________________________________________________________________
batch_normalization_47 (BatchNor (None, 17, 17, 160)   480         conv2d_47[0][0]                  
____________________________________________________________________________________________________
activation_42 (Activation)       (None, 17, 17, 160)   0           batch_normalization_42[0][0]     
____________________________________________________________________________________________________
activation_47 (Activation)       (None, 17, 17, 160)   0           batch_normalization_47[0][0]     
____________________________________________________________________________________________________
conv2d_43 (Conv2D)               (None, 17, 17, 160)   179200      activation_42[0][0]              
____________________________________________________________________________________________________
conv2d_48 (Conv2D)               (None, 17, 17, 160)   179200      activation_47[0][0]              
____________________________________________________________________________________________________
batch_normalization_43 (BatchNor (None, 17, 17, 160)   480         conv2d_43[0][0]                  
____________________________________________________________________________________________________
batch_normalization_48 (BatchNor (None, 17, 17, 160)   480         conv2d_48[0][0]                  
____________________________________________________________________________________________________
activation_43 (Activation)       (None, 17, 17, 160)   0           batch_normalization_43[0][0]     
____________________________________________________________________________________________________
activation_48 (Activation)       (None, 17, 17, 160)   0           batch_normalization_48[0][0]     
____________________________________________________________________________________________________
average_pooling2d_5 (AveragePool (None, 17, 17, 768)   0           mixed4[0][0]                     
____________________________________________________________________________________________________
conv2d_41 (Conv2D)               (None, 17, 17, 192)   147456      mixed4[0][0]                     
____________________________________________________________________________________________________
conv2d_44 (Conv2D)               (None, 17, 17, 192)   215040      activation_43[0][0]              
____________________________________________________________________________________________________
conv2d_49 (Conv2D)               (None, 17, 17, 192)   215040      activation_48[0][0]              
____________________________________________________________________________________________________
conv2d_50 (Conv2D)               (None, 17, 17, 192)   147456      average_pooling2d_5[0][0]        
____________________________________________________________________________________________________
batch_normalization_41 (BatchNor (None, 17, 17, 192)   576         conv2d_41[0][0]                  
____________________________________________________________________________________________________
batch_normalization_44 (BatchNor (None, 17, 17, 192)   576         conv2d_44[0][0]                  
____________________________________________________________________________________________________
batch_normalization_49 (BatchNor (None, 17, 17, 192)   576         conv2d_49[0][0]                  
____________________________________________________________________________________________________
batch_normalization_50 (BatchNor (None, 17, 17, 192)   576         conv2d_50[0][0]                  
____________________________________________________________________________________________________
activation_41 (Activation)       (None, 17, 17, 192)   0           batch_normalization_41[0][0]     
____________________________________________________________________________________________________
activation_44 (Activation)       (None, 17, 17, 192)   0           batch_normalization_44[0][0]     
____________________________________________________________________________________________________
activation_49 (Activation)       (None, 17, 17, 192)   0           batch_normalization_49[0][0]     
____________________________________________________________________________________________________
activation_50 (Activation)       (None, 17, 17, 192)   0           batch_normalization_50[0][0]     
____________________________________________________________________________________________________
mixed5 (Concatenate)             (None, 17, 17, 768)   0           activation_41[0][0]              
                                                                   activation_44[0][0]              
                                                                   activation_49[0][0]              
                                                                   activation_50[0][0]              
____________________________________________________________________________________________________
conv2d_55 (Conv2D)               (None, 17, 17, 160)   122880      mixed5[0][0]                     
____________________________________________________________________________________________________
batch_normalization_55 (BatchNor (None, 17, 17, 160)   480         conv2d_55[0][0]                  
____________________________________________________________________________________________________
activation_55 (Activation)       (None, 17, 17, 160)   0           batch_normalization_55[0][0]     
____________________________________________________________________________________________________
conv2d_56 (Conv2D)               (None, 17, 17, 160)   179200      activation_55[0][0]              
____________________________________________________________________________________________________
batch_normalization_56 (BatchNor (None, 17, 17, 160)   480         conv2d_56[0][0]                  
____________________________________________________________________________________________________
activation_56 (Activation)       (None, 17, 17, 160)   0           batch_normalization_56[0][0]     
____________________________________________________________________________________________________
conv2d_52 (Conv2D)               (None, 17, 17, 160)   122880      mixed5[0][0]                     
____________________________________________________________________________________________________
conv2d_57 (Conv2D)               (None, 17, 17, 160)   179200      activation_56[0][0]              
____________________________________________________________________________________________________
batch_normalization_52 (BatchNor (None, 17, 17, 160)   480         conv2d_52[0][0]                  
____________________________________________________________________________________________________
batch_normalization_57 (BatchNor (None, 17, 17, 160)   480         conv2d_57[0][0]                  
____________________________________________________________________________________________________
activation_52 (Activation)       (None, 17, 17, 160)   0           batch_normalization_52[0][0]     
____________________________________________________________________________________________________
activation_57 (Activation)       (None, 17, 17, 160)   0           batch_normalization_57[0][0]     
____________________________________________________________________________________________________
conv2d_53 (Conv2D)               (None, 17, 17, 160)   179200      activation_52[0][0]              
____________________________________________________________________________________________________
conv2d_58 (Conv2D)               (None, 17, 17, 160)   179200      activation_57[0][0]              
____________________________________________________________________________________________________
batch_normalization_53 (BatchNor (None, 17, 17, 160)   480         conv2d_53[0][0]                  
____________________________________________________________________________________________________
batch_normalization_58 (BatchNor (None, 17, 17, 160)   480         conv2d_58[0][0]                  
____________________________________________________________________________________________________
activation_53 (Activation)       (None, 17, 17, 160)   0           batch_normalization_53[0][0]     
____________________________________________________________________________________________________
activation_58 (Activation)       (None, 17, 17, 160)   0           batch_normalization_58[0][0]     
____________________________________________________________________________________________________
average_pooling2d_6 (AveragePool (None, 17, 17, 768)   0           mixed5[0][0]                     
____________________________________________________________________________________________________
conv2d_51 (Conv2D)               (None, 17, 17, 192)   147456      mixed5[0][0]                     
____________________________________________________________________________________________________
conv2d_54 (Conv2D)               (None, 17, 17, 192)   215040      activation_53[0][0]              
____________________________________________________________________________________________________
conv2d_59 (Conv2D)               (None, 17, 17, 192)   215040      activation_58[0][0]              
____________________________________________________________________________________________________
conv2d_60 (Conv2D)               (None, 17, 17, 192)   147456      average_pooling2d_6[0][0]        
____________________________________________________________________________________________________
batch_normalization_51 (BatchNor (None, 17, 17, 192)   576         conv2d_51[0][0]                  
____________________________________________________________________________________________________
batch_normalization_54 (BatchNor (None, 17, 17, 192)   576         conv2d_54[0][0]                  
____________________________________________________________________________________________________
batch_normalization_59 (BatchNor (None, 17, 17, 192)   576         conv2d_59[0][0]                  
____________________________________________________________________________________________________
batch_normalization_60 (BatchNor (None, 17, 17, 192)   576         conv2d_60[0][0]                  
____________________________________________________________________________________________________
activation_51 (Activation)       (None, 17, 17, 192)   0           batch_normalization_51[0][0]     
____________________________________________________________________________________________________
activation_54 (Activation)       (None, 17, 17, 192)   0           batch_normalization_54[0][0]     
____________________________________________________________________________________________________
activation_59 (Activation)       (None, 17, 17, 192)   0           batch_normalization_59[0][0]     
____________________________________________________________________________________________________
activation_60 (Activation)       (None, 17, 17, 192)   0           batch_normalization_60[0][0]     
____________________________________________________________________________________________________
mixed6 (Concatenate)             (None, 17, 17, 768)   0           activation_51[0][0]              
                                                                   activation_54[0][0]              
                                                                   activation_59[0][0]              
                                                                   activation_60[0][0]              
____________________________________________________________________________________________________
conv2d_65 (Conv2D)               (None, 17, 17, 192)   147456      mixed6[0][0]                     
____________________________________________________________________________________________________
batch_normalization_65 (BatchNor (None, 17, 17, 192)   576         conv2d_65[0][0]                  
____________________________________________________________________________________________________
activation_65 (Activation)       (None, 17, 17, 192)   0           batch_normalization_65[0][0]     
____________________________________________________________________________________________________
conv2d_66 (Conv2D)               (None, 17, 17, 192)   258048      activation_65[0][0]              
____________________________________________________________________________________________________
batch_normalization_66 (BatchNor (None, 17, 17, 192)   576         conv2d_66[0][0]                  
____________________________________________________________________________________________________
activation_66 (Activation)       (None, 17, 17, 192)   0           batch_normalization_66[0][0]     
____________________________________________________________________________________________________
conv2d_62 (Conv2D)               (None, 17, 17, 192)   147456      mixed6[0][0]                     
____________________________________________________________________________________________________
conv2d_67 (Conv2D)               (None, 17, 17, 192)   258048      activation_66[0][0]              
____________________________________________________________________________________________________
batch_normalization_62 (BatchNor (None, 17, 17, 192)   576         conv2d_62[0][0]                  
____________________________________________________________________________________________________
batch_normalization_67 (BatchNor (None, 17, 17, 192)   576         conv2d_67[0][0]                  
____________________________________________________________________________________________________
activation_62 (Activation)       (None, 17, 17, 192)   0           batch_normalization_62[0][0]     
____________________________________________________________________________________________________
activation_67 (Activation)       (None, 17, 17, 192)   0           batch_normalization_67[0][0]     
____________________________________________________________________________________________________
conv2d_63 (Conv2D)               (None, 17, 17, 192)   258048      activation_62[0][0]              
____________________________________________________________________________________________________
conv2d_68 (Conv2D)               (None, 17, 17, 192)   258048      activation_67[0][0]              
____________________________________________________________________________________________________
batch_normalization_63 (BatchNor (None, 17, 17, 192)   576         conv2d_63[0][0]                  
____________________________________________________________________________________________________
batch_normalization_68 (BatchNor (None, 17, 17, 192)   576         conv2d_68[0][0]                  
____________________________________________________________________________________________________
activation_63 (Activation)       (None, 17, 17, 192)   0           batch_normalization_63[0][0]     
____________________________________________________________________________________________________
activation_68 (Activation)       (None, 17, 17, 192)   0           batch_normalization_68[0][0]     
____________________________________________________________________________________________________
average_pooling2d_7 (AveragePool (None, 17, 17, 768)   0           mixed6[0][0]                     
____________________________________________________________________________________________________
conv2d_61 (Conv2D)               (None, 17, 17, 192)   147456      mixed6[0][0]                     
____________________________________________________________________________________________________
conv2d_64 (Conv2D)               (None, 17, 17, 192)   258048      activation_63[0][0]              
____________________________________________________________________________________________________
conv2d_69 (Conv2D)               (None, 17, 17, 192)   258048      activation_68[0][0]              
____________________________________________________________________________________________________
conv2d_70 (Conv2D)               (None, 17, 17, 192)   147456      average_pooling2d_7[0][0]        
____________________________________________________________________________________________________
batch_normalization_61 (BatchNor (None, 17, 17, 192)   576         conv2d_61[0][0]                  
____________________________________________________________________________________________________
batch_normalization_64 (BatchNor (None, 17, 17, 192)   576         conv2d_64[0][0]                  
____________________________________________________________________________________________________
batch_normalization_69 (BatchNor (None, 17, 17, 192)   576         conv2d_69[0][0]                  
____________________________________________________________________________________________________
batch_normalization_70 (BatchNor (None, 17, 17, 192)   576         conv2d_70[0][0]                  
____________________________________________________________________________________________________
activation_61 (Activation)       (None, 17, 17, 192)   0           batch_normalization_61[0][0]     
____________________________________________________________________________________________________
activation_64 (Activation)       (None, 17, 17, 192)   0           batch_normalization_64[0][0]     
____________________________________________________________________________________________________
activation_69 (Activation)       (None, 17, 17, 192)   0           batch_normalization_69[0][0]     
____________________________________________________________________________________________________
activation_70 (Activation)       (None, 17, 17, 192)   0           batch_normalization_70[0][0]     
____________________________________________________________________________________________________
mixed7 (Concatenate)             (None, 17, 17, 768)   0           activation_61[0][0]              
                                                                   activation_64[0][0]              
                                                                   activation_69[0][0]              
                                                                   activation_70[0][0]              
____________________________________________________________________________________________________
conv2d_73 (Conv2D)               (None, 17, 17, 192)   147456      mixed7[0][0]                     
____________________________________________________________________________________________________
batch_normalization_73 (BatchNor (None, 17, 17, 192)   576         conv2d_73[0][0]                  
____________________________________________________________________________________________________
activation_73 (Activation)       (None, 17, 17, 192)   0           batch_normalization_73[0][0]     
____________________________________________________________________________________________________
conv2d_74 (Conv2D)               (None, 17, 17, 192)   258048      activation_73[0][0]              
____________________________________________________________________________________________________
batch_normalization_74 (BatchNor (None, 17, 17, 192)   576         conv2d_74[0][0]                  
____________________________________________________________________________________________________
activation_74 (Activation)       (None, 17, 17, 192)   0           batch_normalization_74[0][0]     
____________________________________________________________________________________________________
conv2d_71 (Conv2D)               (None, 17, 17, 192)   147456      mixed7[0][0]                     
____________________________________________________________________________________________________
conv2d_75 (Conv2D)               (None, 17, 17, 192)   258048      activation_74[0][0]              
____________________________________________________________________________________________________
batch_normalization_71 (BatchNor (None, 17, 17, 192)   576         conv2d_71[0][0]                  
____________________________________________________________________________________________________
batch_normalization_75 (BatchNor (None, 17, 17, 192)   576         conv2d_75[0][0]                  
____________________________________________________________________________________________________
activation_71 (Activation)       (None, 17, 17, 192)   0           batch_normalization_71[0][0]     
____________________________________________________________________________________________________
activation_75 (Activation)       (None, 17, 17, 192)   0           batch_normalization_75[0][0]     
____________________________________________________________________________________________________
conv2d_72 (Conv2D)               (None, 8, 8, 320)     552960      activation_71[0][0]              
____________________________________________________________________________________________________
conv2d_76 (Conv2D)               (None, 8, 8, 192)     331776      activation_75[0][0]              
____________________________________________________________________________________________________
batch_normalization_72 (BatchNor (None, 8, 8, 320)     960         conv2d_72[0][0]                  
____________________________________________________________________________________________________
batch_normalization_76 (BatchNor (None, 8, 8, 192)     576         conv2d_76[0][0]                  
____________________________________________________________________________________________________
activation_72 (Activation)       (None, 8, 8, 320)     0           batch_normalization_72[0][0]     
____________________________________________________________________________________________________
activation_76 (Activation)       (None, 8, 8, 192)     0           batch_normalization_76[0][0]     
____________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)   (None, 8, 8, 768)     0           mixed7[0][0]                     
____________________________________________________________________________________________________
mixed8 (Concatenate)             (None, 8, 8, 1280)    0           activation_72[0][0]              
                                                                   activation_76[0][0]              
                                                                   max_pooling2d_4[0][0]            
____________________________________________________________________________________________________
conv2d_81 (Conv2D)               (None, 8, 8, 448)     573440      mixed8[0][0]                     
____________________________________________________________________________________________________
batch_normalization_81 (BatchNor (None, 8, 8, 448)     1344        conv2d_81[0][0]                  
____________________________________________________________________________________________________
activation_81 (Activation)       (None, 8, 8, 448)     0           batch_normalization_81[0][0]     
____________________________________________________________________________________________________
conv2d_78 (Conv2D)               (None, 8, 8, 384)     491520      mixed8[0][0]                     
____________________________________________________________________________________________________
conv2d_82 (Conv2D)               (None, 8, 8, 384)     1548288     activation_81[0][0]              
____________________________________________________________________________________________________
batch_normalization_78 (BatchNor (None, 8, 8, 384)     1152        conv2d_78[0][0]                  
____________________________________________________________________________________________________
batch_normalization_82 (BatchNor (None, 8, 8, 384)     1152        conv2d_82[0][0]                  
____________________________________________________________________________________________________
activation_78 (Activation)       (None, 8, 8, 384)     0           batch_normalization_78[0][0]     
____________________________________________________________________________________________________
activation_82 (Activation)       (None, 8, 8, 384)     0           batch_normalization_82[0][0]     
____________________________________________________________________________________________________
conv2d_79 (Conv2D)               (None, 8, 8, 384)     442368      activation_78[0][0]              
____________________________________________________________________________________________________
conv2d_80 (Conv2D)               (None, 8, 8, 384)     442368      activation_78[0][0]              
____________________________________________________________________________________________________
conv2d_83 (Conv2D)               (None, 8, 8, 384)     442368      activation_82[0][0]              
____________________________________________________________________________________________________
conv2d_84 (Conv2D)               (None, 8, 8, 384)     442368      activation_82[0][0]              
____________________________________________________________________________________________________
average_pooling2d_8 (AveragePool (None, 8, 8, 1280)    0           mixed8[0][0]                     
____________________________________________________________________________________________________
conv2d_77 (Conv2D)               (None, 8, 8, 320)     409600      mixed8[0][0]                     
____________________________________________________________________________________________________
batch_normalization_79 (BatchNor (None, 8, 8, 384)     1152        conv2d_79[0][0]                  
____________________________________________________________________________________________________
batch_normalization_80 (BatchNor (None, 8, 8, 384)     1152        conv2d_80[0][0]                  
____________________________________________________________________________________________________
batch_normalization_83 (BatchNor (None, 8, 8, 384)     1152        conv2d_83[0][0]                  
____________________________________________________________________________________________________
batch_normalization_84 (BatchNor (None, 8, 8, 384)     1152        conv2d_84[0][0]                  
____________________________________________________________________________________________________
conv2d_85 (Conv2D)               (None, 8, 8, 192)     245760      average_pooling2d_8[0][0]        
____________________________________________________________________________________________________
batch_normalization_77 (BatchNor (None, 8, 8, 320)     960         conv2d_77[0][0]                  
____________________________________________________________________________________________________
activation_79 (Activation)       (None, 8, 8, 384)     0           batch_normalization_79[0][0]     
____________________________________________________________________________________________________
activation_80 (Activation)       (None, 8, 8, 384)     0           batch_normalization_80[0][0]     
____________________________________________________________________________________________________
activation_83 (Activation)       (None, 8, 8, 384)     0           batch_normalization_83[0][0]     
____________________________________________________________________________________________________
activation_84 (Activation)       (None, 8, 8, 384)     0           batch_normalization_84[0][0]     
____________________________________________________________________________________________________
batch_normalization_85 (BatchNor (None, 8, 8, 192)     576         conv2d_85[0][0]                  
____________________________________________________________________________________________________
activation_77 (Activation)       (None, 8, 8, 320)     0           batch_normalization_77[0][0]     
____________________________________________________________________________________________________
mixed9_0 (Concatenate)           (None, 8, 8, 768)     0           activation_79[0][0]              
                                                                   activation_80[0][0]              
____________________________________________________________________________________________________
concatenate_1 (Concatenate)      (None, 8, 8, 768)     0           activation_83[0][0]              
                                                                   activation_84[0][0]              
____________________________________________________________________________________________________
activation_85 (Activation)       (None, 8, 8, 192)     0           batch_normalization_85[0][0]     
____________________________________________________________________________________________________
mixed9 (Concatenate)             (None, 8, 8, 2048)    0           activation_77[0][0]              
                                                                   mixed9_0[0][0]                   
                                                                   concatenate_1[0][0]              
                                                                   activation_85[0][0]              
____________________________________________________________________________________________________
conv2d_90 (Conv2D)               (None, 8, 8, 448)     917504      mixed9[0][0]                     
____________________________________________________________________________________________________
batch_normalization_90 (BatchNor (None, 8, 8, 448)     1344        conv2d_90[0][0]                  
____________________________________________________________________________________________________
activation_90 (Activation)       (None, 8, 8, 448)     0           batch_normalization_90[0][0]     
____________________________________________________________________________________________________
conv2d_87 (Conv2D)               (None, 8, 8, 384)     786432      mixed9[0][0]                     
____________________________________________________________________________________________________
conv2d_91 (Conv2D)               (None, 8, 8, 384)     1548288     activation_90[0][0]              
____________________________________________________________________________________________________
batch_normalization_87 (BatchNor (None, 8, 8, 384)     1152        conv2d_87[0][0]                  
____________________________________________________________________________________________________
batch_normalization_91 (BatchNor (None, 8, 8, 384)     1152        conv2d_91[0][0]                  
____________________________________________________________________________________________________
activation_87 (Activation)       (None, 8, 8, 384)     0           batch_normalization_87[0][0]     
____________________________________________________________________________________________________
activation_91 (Activation)       (None, 8, 8, 384)     0           batch_normalization_91[0][0]     
____________________________________________________________________________________________________
conv2d_88 (Conv2D)               (None, 8, 8, 384)     442368      activation_87[0][0]              
____________________________________________________________________________________________________
conv2d_89 (Conv2D)               (None, 8, 8, 384)     442368      activation_87[0][0]              
____________________________________________________________________________________________________
conv2d_92 (Conv2D)               (None, 8, 8, 384)     442368      activation_91[0][0]              
____________________________________________________________________________________________________
conv2d_93 (Conv2D)               (None, 8, 8, 384)     442368      activation_91[0][0]              
____________________________________________________________________________________________________
average_pooling2d_9 (AveragePool (None, 8, 8, 2048)    0           mixed9[0][0]                     
____________________________________________________________________________________________________
conv2d_86 (Conv2D)               (None, 8, 8, 320)     655360      mixed9[0][0]                     
____________________________________________________________________________________________________
batch_normalization_88 (BatchNor (None, 8, 8, 384)     1152        conv2d_88[0][0]                  
____________________________________________________________________________________________________
batch_normalization_89 (BatchNor (None, 8, 8, 384)     1152        conv2d_89[0][0]                  
____________________________________________________________________________________________________
batch_normalization_92 (BatchNor (None, 8, 8, 384)     1152        conv2d_92[0][0]                  
____________________________________________________________________________________________________
batch_normalization_93 (BatchNor (None, 8, 8, 384)     1152        conv2d_93[0][0]                  
____________________________________________________________________________________________________
conv2d_94 (Conv2D)               (None, 8, 8, 192)     393216      average_pooling2d_9[0][0]        
____________________________________________________________________________________________________
batch_normalization_86 (BatchNor (None, 8, 8, 320)     960         conv2d_86[0][0]                  
____________________________________________________________________________________________________
activation_88 (Activation)       (None, 8, 8, 384)     0           batch_normalization_88[0][0]     
____________________________________________________________________________________________________
activation_89 (Activation)       (None, 8, 8, 384)     0           batch_normalization_89[0][0]     
____________________________________________________________________________________________________
activation_92 (Activation)       (None, 8, 8, 384)     0           batch_normalization_92[0][0]     
____________________________________________________________________________________________________
activation_93 (Activation)       (None, 8, 8, 384)     0           batch_normalization_93[0][0]     
____________________________________________________________________________________________________
batch_normalization_94 (BatchNor (None, 8, 8, 192)     576         conv2d_94[0][0]                  
____________________________________________________________________________________________________
activation_86 (Activation)       (None, 8, 8, 320)     0           batch_normalization_86[0][0]     
____________________________________________________________________________________________________
mixed9_1 (Concatenate)           (None, 8, 8, 768)     0           activation_88[0][0]              
                                                                   activation_89[0][0]              
____________________________________________________________________________________________________
concatenate_2 (Concatenate)      (None, 8, 8, 768)     0           activation_92[0][0]              
                                                                   activation_93[0][0]              
____________________________________________________________________________________________________
activation_94 (Activation)       (None, 8, 8, 192)     0           batch_normalization_94[0][0]     
____________________________________________________________________________________________________
mixed10 (Concatenate)            (None, 8, 8, 2048)    0           activation_86[0][0]              
                                                                   mixed9_1[0][0]                   
                                                                   concatenate_2[0][0]              
                                                                   activation_94[0][0]              
____________________________________________________________________________________________________
global_average_pooling2d_1 (Glob (None, 2048)          0           mixed10[0][0]                    
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 3)             6147        global_average_pooling2d_1[0][0] 
====================================================================================================
Total params: 21,808,931
Trainable params: 21,774,499
Non-trainable params: 34,432
____________________________________________________________________________________________________
Found 455 images belonging to 3 classes.
Found 116 images belonging to 3 classes.
Found 130 images belonging to 3 classes.
Epoch 1/150
 1/14 [=>............................] - ETA: 79s - loss: 1.0508 - acc: 0.5625 2/14 [===>..........................] - ETA: 38s - loss: 1.0959 - acc: 0.5156 3/14 [=====>........................] - ETA: 25s - loss: 1.1113 - acc: 0.4583 4/14 [=======>......................] - ETA: 17s - loss: 1.0849 - acc: 0.4531 5/14 [=========>....................] - ETA: 13s - loss: 1.0829 - acc: 0.4437 6/14 [===========>..................] - ETA: 10s - loss: 1.0999 - acc: 0.4219 7/14 [==============>...............] - ETA: 8s - loss: 1.0998 - acc: 0.4241  8/14 [================>.............] - ETA: 6s - loss: 1.0956 - acc: 0.4219 9/14 [==================>...........] - ETA: 4s - loss: 1.0687 - acc: 0.447910/14 [====================>.........] - ETA: 3s - loss: 1.0504 - acc: 0.468811/14 [======================>.......] - ETA: 2s - loss: 1.0560 - acc: 0.457412/14 [========================>.....] - ETA: 1s - loss: 1.0515 - acc: 0.460913/14 [==========================>...] - ETA: 0s - loss: 1.0350 - acc: 0.4760Epoch 00000: val_acc improved from -inf to 0.50000, saving model to /mnt/Data/ltanzi/networksForCam/Fold1_InceptionforCAMA1A2A3-best_model.h5
14/14 [==============================] - 29s - loss: 1.0210 - acc: 0.4911 - val_loss: 0.9793 - val_acc: 0.5000
Epoch 2/150
 1/14 [=>............................] - ETA: 6s - loss: 0.9463 - acc: 0.5714 2/14 [===>..........................] - ETA: 4s - loss: 0.9512 - acc: 0.5826 3/14 [=====>........................] - ETA: 4s - loss: 0.8527 - acc: 0.6488 4/14 [=======>......................] - ETA: 3s - loss: 0.7943 - acc: 0.6819 5/14 [=========>....................] - ETA: 3s - loss: 0.7604 - acc: 0.6955 6/14 [===========>..................] - ETA: 2s - loss: 0.7485 - acc: 0.6890 7/14 [==============>...............] - ETA: 2s - loss: 0.7291 - acc: 0.7022 8/14 [================>.............] - ETA: 2s - loss: 0.7192 - acc: 0.7081 9/14 [==================>...........] - ETA: 1s - loss: 0.7092 - acc: 0.705910/14 [====================>.........] - ETA: 1s - loss: 0.7021 - acc: 0.707111/14 [======================>.......] - ETA: 1s - loss: 0.6977 - acc: 0.705412/14 [========================>.....] - ETA: 0s - loss: 0.6893 - acc: 0.706513/14 [==========================>...] - ETA: 0s - loss: 0.6916 - acc: 0.7002Epoch 00001: val_acc improved from 0.50000 to 0.54167, saving model to /mnt/Data/ltanzi/networksForCam/Fold1_InceptionforCAMA1A2A3-best_model.h5
14/14 [==============================] - 8s - loss: 0.6705 - acc: 0.7088 - val_loss: 0.8521 - val_acc: 0.5417
Epoch 3/150
 1/14 [=>............................] - ETA: 4s - loss: 0.5186 - acc: 0.8125 2/14 [===>..........................] - ETA: 2s - loss: 0.5110 - acc: 0.8348 3/14 [=====>........................] - ETA: 3s - loss: 0.4999 - acc: 0.8378 4/14 [=======>......................] - ETA: 3s - loss: 0.4957 - acc: 0.8237 5/14 [=========>....................] - ETA: 3s - loss: 0.4665 - acc: 0.8214 6/14 [===========>..................] - ETA: 2s - loss: 0.4419 - acc: 0.8408 7/14 [==============>...............] - ETA: 2s - loss: 0.4349 - acc: 0.8501 8/14 [================>.............] - ETA: 2s - loss: 0.4292 - acc: 0.8493 9/14 [==================>...........] - ETA: 2s - loss: 0.4533 - acc: 0.841810/14 [====================>.........] - ETA: 1s - loss: 0.4747 - acc: 0.829511/14 [======================>.......] - ETA: 1s - loss: 0.4649 - acc: 0.827912/14 [========================>.....] - ETA: 1s - loss: 0.4558 - acc: 0.829213/14 [==========================>...] - ETA: 0s - loss: 0.4590 - acc: 0.8207Epoch 00002: val_acc improved from 0.54167 to 0.62500, saving model to /mnt/Data/ltanzi/networksForCam/Fold1_InceptionforCAMA1A2A3-best_model.h5
14/14 [==============================] - 12s - loss: 0.4684 - acc: 0.8133 - val_loss: 0.8099 - val_acc: 0.6250
Epoch 4/150
 1/14 [=>............................] - ETA: 4s - loss: 0.4361 - acc: 0.8125 2/14 [===>..........................] - ETA: 4s - loss: 0.3895 - acc: 0.8125 3/14 [=====>........................] - ETA: 2s - loss: 0.3720 - acc: 0.8274 4/14 [=======>......................] - ETA: 2s - loss: 0.3396 - acc: 0.8627 5/14 [=========>....................] - ETA: 3s - loss: 0.3283 - acc: 0.8527 6/14 [===========>..................] - ETA: 3s - loss: 0.3512 - acc: 0.8564 7/14 [==============>...............] - ETA: 3s - loss: 0.3611 - acc: 0.8501 8/14 [================>.............] - ETA: 3s - loss: 0.3395 - acc: 0.8610 9/14 [==================>...........] - ETA: 2s - loss: 0.3267 - acc: 0.866110/14 [====================>.........] - ETA: 2s - loss: 0.3238 - acc: 0.873211/14 [======================>.......] - ETA: 1s - loss: 0.3080 - acc: 0.881912/14 [========================>.....] - ETA: 1s - loss: 0.3123 - acc: 0.881313/14 [==========================>...] - ETA: 0s - loss: 0.3055 - acc: 0.8856Epoch 00003: val_acc improved from 0.62500 to 0.66667, saving model to /mnt/Data/ltanzi/networksForCam/Fold1_InceptionforCAMA1A2A3-best_model.h5
14/14 [==============================] - 12s - loss: 0.2909 - acc: 0.8940 - val_loss: 0.7359 - val_acc: 0.6667
Epoch 5/150
 1/14 [=>............................] - ETA: 4s - loss: 0.2244 - acc: 0.9375 2/14 [===>..........................] - ETA: 4s - loss: 0.2454 - acc: 0.9375 3/14 [=====>........................] - ETA: 3s - loss: 0.2280 - acc: 0.9271 4/14 [=======>......................] - ETA: 2s - loss: 0.2712 - acc: 0.9096 5/14 [=========>....................] - ETA: 3s - loss: 0.2393 - acc: 0.9214 6/14 [===========>..................] - ETA: 3s - loss: 0.2255 - acc: 0.9241 7/14 [==============>...............] - ETA: 3s - loss: 0.2261 - acc: 0.9260 8/14 [================>.............] - ETA: 3s - loss: 0.2087 - acc: 0.9314 9/14 [==================>...........] - ETA: 2s - loss: 0.2123 - acc: 0.921610/14 [====================>.........] - ETA: 2s - loss: 0.2135 - acc: 0.917011/14 [======================>.......] - ETA: 1s - loss: 0.2025 - acc: 0.924512/14 [========================>.....] - ETA: 1s - loss: 0.2012 - acc: 0.925613/14 [==========================>...] - ETA: 0s - loss: 0.1915 - acc: 0.9313Epoch 00004: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.1862 - acc: 0.9343 - val_loss: 0.7593 - val_acc: 0.6562
Epoch 6/150
 1/14 [=>............................] - ETA: 4s - loss: 0.2332 - acc: 0.8750 2/14 [===>..........................] - ETA: 4s - loss: 0.1892 - acc: 0.9062 3/14 [=====>........................] - ETA: 3s - loss: 0.2030 - acc: 0.9062 4/14 [=======>......................] - ETA: 4s - loss: 0.1917 - acc: 0.9141 5/14 [=========>....................] - ETA: 3s - loss: 0.3811 - acc: 0.8741 6/14 [===========>..................] - ETA: 3s - loss: 0.3757 - acc: 0.8743 7/14 [==============>...............] - ETA: 3s - loss: 0.3615 - acc: 0.8744 8/14 [================>.............] - ETA: 3s - loss: 0.3247 - acc: 0.8862 9/14 [==================>...........] - ETA: 2s - loss: 0.3008 - acc: 0.895310/14 [====================>.........] - ETA: 2s - loss: 0.2873 - acc: 0.899611/14 [======================>.......] - ETA: 1s - loss: 0.2748 - acc: 0.903012/14 [========================>.....] - ETA: 1s - loss: 0.2608 - acc: 0.908513/14 [==========================>...] - ETA: 0s - loss: 0.2549 - acc: 0.9107Epoch 00005: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.2544 - acc: 0.9112 - val_loss: 0.8743 - val_acc: 0.6458
Epoch 7/150
 1/14 [=>............................] - ETA: 4s - loss: 0.2463 - acc: 0.8750 2/14 [===>..........................] - ETA: 4s - loss: 0.3126 - acc: 0.9062 3/14 [=====>........................] - ETA: 3s - loss: 0.2608 - acc: 0.9271 4/14 [=======>......................] - ETA: 4s - loss: 0.2384 - acc: 0.9297 5/14 [=========>....................] - ETA: 4s - loss: 0.2131 - acc: 0.9375 6/14 [===========>..................] - ETA: 3s - loss: 0.1939 - acc: 0.9479 7/14 [==============>...............] - ETA: 3s - loss: 0.2025 - acc: 0.9464 8/14 [================>.............] - ETA: 3s - loss: 0.1932 - acc: 0.9453 9/14 [==================>...........] - ETA: 2s - loss: 0.1800 - acc: 0.951410/14 [====================>.........] - ETA: 2s - loss: 0.1766 - acc: 0.950011/14 [======================>.......] - ETA: 1s - loss: 0.1795 - acc: 0.948912/14 [========================>.....] - ETA: 1s - loss: 0.1755 - acc: 0.947913/14 [==========================>...] - ETA: 0s - loss: 0.1708 - acc: 0.9495Epoch 00006: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.1638 - acc: 0.9507 - val_loss: 0.9548 - val_acc: 0.6458
Epoch 8/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0279 - acc: 1.0000 2/14 [===>..........................] - ETA: 4s - loss: 0.1072 - acc: 0.9844 3/14 [=====>........................] - ETA: 3s - loss: 0.1497 - acc: 0.9583 4/14 [=======>......................] - ETA: 4s - loss: 0.1674 - acc: 0.9453 5/14 [=========>....................] - ETA: 4s - loss: 0.1641 - acc: 0.9437 6/14 [===========>..................] - ETA: 4s - loss: 0.1617 - acc: 0.9427 7/14 [==============>...............] - ETA: 3s - loss: 0.1840 - acc: 0.9305 8/14 [================>.............] - ETA: 3s - loss: 0.1816 - acc: 0.9353 9/14 [==================>...........] - ETA: 2s - loss: 0.1774 - acc: 0.935510/14 [====================>.........] - ETA: 2s - loss: 0.1691 - acc: 0.935711/14 [======================>.......] - ETA: 1s - loss: 0.1617 - acc: 0.935912/14 [========================>.....] - ETA: 1s - loss: 0.1536 - acc: 0.938613/14 [==========================>...] - ETA: 0s - loss: 0.1619 - acc: 0.9385Epoch 00007: val_acc improved from 0.66667 to 0.71875, saving model to /mnt/Data/ltanzi/networksForCam/Fold1_InceptionforCAMA1A2A3-best_model.h5
14/14 [==============================] - 12s - loss: 0.1520 - acc: 0.9433 - val_loss: 0.7659 - val_acc: 0.7188
Epoch 9/150
 1/14 [=>............................] - ETA: 4s - loss: 0.2781 - acc: 0.8750 2/14 [===>..........................] - ETA: 4s - loss: 0.1744 - acc: 0.9219 3/14 [=====>........................] - ETA: 3s - loss: 0.1314 - acc: 0.9479 4/14 [=======>......................] - ETA: 3s - loss: 0.1079 - acc: 0.9609 5/14 [=========>....................] - ETA: 4s - loss: 0.1056 - acc: 0.9563 6/14 [===========>..................] - ETA: 4s - loss: 0.1119 - acc: 0.9583 7/14 [==============>...............] - ETA: 4s - loss: 0.1118 - acc: 0.9554 8/14 [================>.............] - ETA: 3s - loss: 0.1103 - acc: 0.9609 9/14 [==================>...........] - ETA: 2s - loss: 0.1051 - acc: 0.961810/14 [====================>.........] - ETA: 2s - loss: 0.1046 - acc: 0.965611/14 [======================>.......] - ETA: 1s - loss: 0.1020 - acc: 0.965912/14 [========================>.....] - ETA: 1s - loss: 0.1059 - acc: 0.966113/14 [==========================>...] - ETA: 0s - loss: 0.1043 - acc: 0.9639Epoch 00008: val_acc improved from 0.71875 to 0.73958, saving model to /mnt/Data/ltanzi/networksForCam/Fold1_InceptionforCAMA1A2A3-best_model.h5
14/14 [==============================] - 12s - loss: 0.0990 - acc: 0.9664 - val_loss: 0.7212 - val_acc: 0.7396
Epoch 10/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0199 - acc: 1.0000 2/14 [===>..........................] - ETA: 4s - loss: 0.0505 - acc: 1.0000 3/14 [=====>........................] - ETA: 3s - loss: 0.0876 - acc: 0.9688 4/14 [=======>......................] - ETA: 3s - loss: 0.1060 - acc: 0.9688 5/14 [=========>....................] - ETA: 4s - loss: 0.0964 - acc: 0.9750 6/14 [===========>..................] - ETA: 4s - loss: 0.0919 - acc: 0.9792 7/14 [==============>...............] - ETA: 4s - loss: 0.0915 - acc: 0.9777 8/14 [================>.............] - ETA: 3s - loss: 0.0839 - acc: 0.9805 9/14 [==================>...........] - ETA: 2s - loss: 0.1545 - acc: 0.966810/14 [====================>.........] - ETA: 2s - loss: 0.1417 - acc: 0.970111/14 [======================>.......] - ETA: 1s - loss: 0.1359 - acc: 0.967112/14 [========================>.....] - ETA: 1s - loss: 0.1265 - acc: 0.969913/14 [==========================>...] - ETA: 0s - loss: 0.1247 - acc: 0.9674Epoch 00009: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.1208 - acc: 0.9679 - val_loss: 0.7611 - val_acc: 0.7083
Epoch 11/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0434 - acc: 0.9688 2/14 [===>..........................] - ETA: 4s - loss: 0.1080 - acc: 0.9375 3/14 [=====>........................] - ETA: 3s - loss: 0.1031 - acc: 0.9375 4/14 [=======>......................] - ETA: 4s - loss: 0.1033 - acc: 0.9453 5/14 [=========>....................] - ETA: 4s - loss: 0.0890 - acc: 0.9563 6/14 [===========>..................] - ETA: 4s - loss: 0.0816 - acc: 0.9635 7/14 [==============>...............] - ETA: 4s - loss: 0.0740 - acc: 0.9688 8/14 [================>.............] - ETA: 3s - loss: 0.0702 - acc: 0.9688 9/14 [==================>...........] - ETA: 3s - loss: 0.0883 - acc: 0.965310/14 [====================>.........] - ETA: 2s - loss: 0.0853 - acc: 0.968811/14 [======================>.......] - ETA: 1s - loss: 0.0807 - acc: 0.971612/14 [========================>.....] - ETA: 1s - loss: 0.0816 - acc: 0.971413/14 [==========================>...] - ETA: 0s - loss: 0.0779 - acc: 0.9736Epoch 00010: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0749 - acc: 0.9753 - val_loss: 0.8856 - val_acc: 0.7083
Epoch 12/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0918 - acc: 0.9375 2/14 [===>..........................] - ETA: 4s - loss: 0.1043 - acc: 0.9375 3/14 [=====>........................] - ETA: 3s - loss: 0.0805 - acc: 0.9583 4/14 [=======>......................] - ETA: 4s - loss: 0.0661 - acc: 0.9688 5/14 [=========>....................] - ETA: 4s - loss: 0.0657 - acc: 0.9750 6/14 [===========>..................] - ETA: 4s - loss: 0.0562 - acc: 0.9792 7/14 [==============>...............] - ETA: 4s - loss: 0.0608 - acc: 0.9732 8/14 [================>.............] - ETA: 3s - loss: 0.1000 - acc: 0.9688 9/14 [==================>...........] - ETA: 3s - loss: 0.0953 - acc: 0.972210/14 [====================>.........] - ETA: 2s - loss: 0.0888 - acc: 0.975011/14 [======================>.......] - ETA: 1s - loss: 0.0850 - acc: 0.977312/14 [========================>.....] - ETA: 1s - loss: 0.0795 - acc: 0.979213/14 [==========================>...] - ETA: 0s - loss: 0.0739 - acc: 0.9808Epoch 00011: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0760 - acc: 0.9776 - val_loss: 0.8680 - val_acc: 0.6979
Epoch 13/150
 1/14 [=>............................] - ETA: 4s - loss: 0.2722 - acc: 0.9062 2/14 [===>..........................] - ETA: 4s - loss: 0.1985 - acc: 0.9062 3/14 [=====>........................] - ETA: 3s - loss: 0.1465 - acc: 0.9271 4/14 [=======>......................] - ETA: 4s - loss: 0.1732 - acc: 0.9141 5/14 [=========>....................] - ETA: 4s - loss: 0.1419 - acc: 0.9313 6/14 [===========>..................] - ETA: 4s - loss: 0.1255 - acc: 0.9427 7/14 [==============>...............] - ETA: 4s - loss: 0.1144 - acc: 0.9509 8/14 [================>.............] - ETA: 3s - loss: 0.1109 - acc: 0.9531 9/14 [==================>...........] - ETA: 3s - loss: 0.1032 - acc: 0.958310/14 [====================>.........] - ETA: 2s - loss: 0.1211 - acc: 0.959411/14 [======================>.......] - ETA: 2s - loss: 0.1165 - acc: 0.957412/14 [========================>.....] - ETA: 1s - loss: 0.1544 - acc: 0.937113/14 [==========================>...] - ETA: 0s - loss: 0.1539 - acc: 0.9396Epoch 00012: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.1469 - acc: 0.9425 - val_loss: 0.9320 - val_acc: 0.7396
Epoch 14/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0592 - acc: 0.9688 2/14 [===>..........................] - ETA: 4s - loss: 0.0744 - acc: 0.9688 3/14 [=====>........................] - ETA: 3s - loss: 0.0625 - acc: 0.9688 4/14 [=======>......................] - ETA: 4s - loss: 0.0588 - acc: 0.9688 5/14 [=========>....................] - ETA: 4s - loss: 0.0539 - acc: 0.9750 6/14 [===========>..................] - ETA: 4s - loss: 0.0701 - acc: 0.9740 7/14 [==============>...............] - ETA: 4s - loss: 0.0656 - acc: 0.9777 8/14 [================>.............] - ETA: 3s - loss: 0.0636 - acc: 0.9766 9/14 [==================>...........] - ETA: 3s - loss: 0.0642 - acc: 0.979210/14 [====================>.........] - ETA: 2s - loss: 0.0604 - acc: 0.981211/14 [======================>.......] - ETA: 2s - loss: 0.0570 - acc: 0.983012/14 [========================>.....] - ETA: 1s - loss: 0.0538 - acc: 0.984413/14 [==========================>...] - ETA: 0s - loss: 0.1147 - acc: 0.9636Epoch 00013: val_acc improved from 0.73958 to 0.75000, saving model to /mnt/Data/ltanzi/networksForCam/Fold1_InceptionforCAMA1A2A3-best_model.h5
14/14 [==============================] - 12s - loss: 0.1046 - acc: 0.9672 - val_loss: 0.8487 - val_acc: 0.7500
Epoch 15/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0097 - acc: 1.0000 2/14 [===>..........................] - ETA: 4s - loss: 0.0268 - acc: 0.9844 3/14 [=====>........................] - ETA: 3s - loss: 0.1613 - acc: 0.9271 4/14 [=======>......................] - ETA: 4s - loss: 0.1510 - acc: 0.9297 5/14 [=========>....................] - ETA: 4s - loss: 0.1669 - acc: 0.9313 6/14 [===========>..................] - ETA: 4s - loss: 0.1569 - acc: 0.9323 7/14 [==============>...............] - ETA: 4s - loss: 0.1417 - acc: 0.9420 8/14 [================>.............] - ETA: 3s - loss: 0.1466 - acc: 0.9336 9/14 [==================>...........] - ETA: 3s - loss: 0.1331 - acc: 0.941010/14 [====================>.........] - ETA: 2s - loss: 0.1290 - acc: 0.943711/14 [======================>.......] - ETA: 2s - loss: 0.1398 - acc: 0.940312/14 [========================>.....] - ETA: 1s - loss: 0.1353 - acc: 0.942713/14 [==========================>...] - ETA: 0s - loss: 0.1279 - acc: 0.9471Epoch 00014: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.1202 - acc: 0.9507 - val_loss: 1.0953 - val_acc: 0.6875
Epoch 16/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0748 - acc: 1.0000 2/14 [===>..........................] - ETA: 4s - loss: 0.1401 - acc: 0.9688 3/14 [=====>........................] - ETA: 3s - loss: 0.1391 - acc: 0.9688 4/14 [=======>......................] - ETA: 4s - loss: 0.1115 - acc: 0.9766 5/14 [=========>....................] - ETA: 4s - loss: 0.0943 - acc: 0.9812 6/14 [===========>..................] - ETA: 4s - loss: 0.0899 - acc: 0.9844 7/14 [==============>...............] - ETA: 4s - loss: 0.0818 - acc: 0.9866 8/14 [================>.............] - ETA: 3s - loss: 0.0797 - acc: 0.9844 9/14 [==================>...........] - ETA: 3s - loss: 0.0817 - acc: 0.979210/14 [====================>.........] - ETA: 2s - loss: 0.0916 - acc: 0.971911/14 [======================>.......] - ETA: 2s - loss: 0.1064 - acc: 0.968812/14 [========================>.....] - ETA: 1s - loss: 0.1020 - acc: 0.971413/14 [==========================>...] - ETA: 0s - loss: 0.1038 - acc: 0.9688Epoch 00015: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0971 - acc: 0.9710 - val_loss: 0.9017 - val_acc: 0.6771
Epoch 17/150
 1/14 [=>............................] - ETA: 1s - loss: 0.1880 - acc: 1.0000 2/14 [===>..........................] - ETA: 2s - loss: 0.1015 - acc: 1.0000 3/14 [=====>........................] - ETA: 2s - loss: 0.0816 - acc: 0.9896 4/14 [=======>......................] - ETA: 2s - loss: 0.0711 - acc: 0.9922 5/14 [=========>....................] - ETA: 3s - loss: 0.0645 - acc: 0.9875 6/14 [===========>..................] - ETA: 3s - loss: 0.1248 - acc: 0.9688 7/14 [==============>...............] - ETA: 3s - loss: 0.1122 - acc: 0.9688 8/14 [================>.............] - ETA: 3s - loss: 0.1044 - acc: 0.9688 9/14 [==================>...........] - ETA: 2s - loss: 0.0944 - acc: 0.972210/14 [====================>.........] - ETA: 2s - loss: 0.0977 - acc: 0.968811/14 [======================>.......] - ETA: 1s - loss: 0.0984 - acc: 0.968812/14 [========================>.....] - ETA: 1s - loss: 0.0971 - acc: 0.968813/14 [==========================>...] - ETA: 0s - loss: 0.0992 - acc: 0.9688Epoch 00016: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0960 - acc: 0.9686 - val_loss: 0.9153 - val_acc: 0.7396
Epoch 18/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0411 - acc: 0.9688 2/14 [===>..........................] - ETA: 2s - loss: 0.3558 - acc: 0.7701 3/14 [=====>........................] - ETA: 2s - loss: 0.2453 - acc: 0.8467 4/14 [=======>......................] - ETA: 2s - loss: 0.2040 - acc: 0.8772 5/14 [=========>....................] - ETA: 3s - loss: 0.1717 - acc: 0.9018 6/14 [===========>..................] - ETA: 3s - loss: 0.1518 - acc: 0.9129 7/14 [==============>...............] - ETA: 3s - loss: 0.1441 - acc: 0.9209 8/14 [================>.............] - ETA: 3s - loss: 0.1315 - acc: 0.9308 9/14 [==================>...........] - ETA: 2s - loss: 0.1234 - acc: 0.938510/14 [====================>.........] - ETA: 2s - loss: 0.1147 - acc: 0.941511/14 [======================>.......] - ETA: 1s - loss: 0.1207 - acc: 0.941212/14 [========================>.....] - ETA: 1s - loss: 0.1485 - acc: 0.935613/14 [==========================>...] - ETA: 0s - loss: 0.1579 - acc: 0.9358Epoch 00017: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.1594 - acc: 0.9396 - val_loss: 0.8996 - val_acc: 0.7292
Epoch 19/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0419 - acc: 1.0000 2/14 [===>..........................] - ETA: 4s - loss: 0.0569 - acc: 0.9844 3/14 [=====>........................] - ETA: 2s - loss: 0.0503 - acc: 0.9896 4/14 [=======>......................] - ETA: 2s - loss: 0.0471 - acc: 0.9922 5/14 [=========>....................] - ETA: 3s - loss: 0.0407 - acc: 0.9938 6/14 [===========>..................] - ETA: 3s - loss: 0.0398 - acc: 0.9948 7/14 [==============>...............] - ETA: 3s - loss: 0.0363 - acc: 0.9955 8/14 [================>.............] - ETA: 3s - loss: 0.0471 - acc: 0.9922 9/14 [==================>...........] - ETA: 2s - loss: 0.0603 - acc: 0.989610/14 [====================>.........] - ETA: 2s - loss: 0.0593 - acc: 0.990611/14 [======================>.......] - ETA: 1s - loss: 0.0557 - acc: 0.991512/14 [========================>.....] - ETA: 1s - loss: 0.0564 - acc: 0.989613/14 [==========================>...] - ETA: 0s - loss: 0.0630 - acc: 0.9880Epoch 00018: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0692 - acc: 0.9866 - val_loss: 0.9628 - val_acc: 0.7083
Epoch 20/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0183 - acc: 1.0000 2/14 [===>..........................] - ETA: 4s - loss: 0.0623 - acc: 0.9844 3/14 [=====>........................] - ETA: 3s - loss: 0.0497 - acc: 0.9896 4/14 [=======>......................] - ETA: 2s - loss: 0.3434 - acc: 0.8493 5/14 [=========>....................] - ETA: 3s - loss: 0.2764 - acc: 0.8795 6/14 [===========>..................] - ETA: 3s - loss: 0.2316 - acc: 0.8996 7/14 [==============>...............] - ETA: 3s - loss: 0.2262 - acc: 0.9050 8/14 [================>.............] - ETA: 3s - loss: 0.2005 - acc: 0.9169 9/14 [==================>...........] - ETA: 2s - loss: 0.1794 - acc: 0.926110/14 [====================>.........] - ETA: 2s - loss: 0.1669 - acc: 0.933511/14 [======================>.......] - ETA: 1s - loss: 0.1533 - acc: 0.939512/14 [========================>.....] - ETA: 1s - loss: 0.1602 - acc: 0.936813/14 [==========================>...] - ETA: 0s - loss: 0.1615 - acc: 0.9368Epoch 00019: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.1487 - acc: 0.9411 - val_loss: 0.9436 - val_acc: 0.7396
Epoch 21/150
 1/14 [=>............................] - ETA: 4s - loss: 0.1138 - acc: 0.9688 2/14 [===>..........................] - ETA: 4s - loss: 0.1369 - acc: 0.9688 3/14 [=====>........................] - ETA: 3s - loss: 0.1183 - acc: 0.9688 4/14 [=======>......................] - ETA: 4s - loss: 0.1049 - acc: 0.9688 5/14 [=========>....................] - ETA: 3s - loss: 0.1394 - acc: 0.9464 6/14 [===========>..................] - ETA: 3s - loss: 0.1222 - acc: 0.9554 7/14 [==============>...............] - ETA: 3s - loss: 0.1062 - acc: 0.9617 8/14 [================>.............] - ETA: 3s - loss: 0.0990 - acc: 0.9665 9/14 [==================>...........] - ETA: 2s - loss: 0.0933 - acc: 0.966810/14 [====================>.........] - ETA: 2s - loss: 0.0885 - acc: 0.970111/14 [======================>.......] - ETA: 1s - loss: 0.0934 - acc: 0.967112/14 [========================>.....] - ETA: 1s - loss: 0.0927 - acc: 0.967313/14 [==========================>...] - ETA: 0s - loss: 0.0870 - acc: 0.9698Epoch 00020: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0913 - acc: 0.9679 - val_loss: 1.0365 - val_acc: 0.7500
Epoch 22/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0237 - acc: 1.0000 2/14 [===>..........................] - ETA: 4s - loss: 0.0352 - acc: 1.0000 3/14 [=====>........................] - ETA: 3s - loss: 0.0368 - acc: 1.0000 4/14 [=======>......................] - ETA: 4s - loss: 0.0297 - acc: 1.0000 5/14 [=========>....................] - ETA: 4s - loss: 0.0266 - acc: 1.0000 6/14 [===========>..................] - ETA: 3s - loss: 0.0614 - acc: 0.9762 7/14 [==============>...............] - ETA: 3s - loss: 0.0593 - acc: 0.9796 8/14 [================>.............] - ETA: 3s - loss: 0.0544 - acc: 0.9821 9/14 [==================>...........] - ETA: 2s - loss: 0.0609 - acc: 0.977210/14 [====================>.........] - ETA: 2s - loss: 0.0593 - acc: 0.976311/14 [======================>.......] - ETA: 1s - loss: 0.0611 - acc: 0.975612/14 [========================>.....] - ETA: 1s - loss: 0.0643 - acc: 0.972513/14 [==========================>...] - ETA: 0s - loss: 0.0663 - acc: 0.9722Epoch 00021: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0621 - acc: 0.9746 - val_loss: 0.9409 - val_acc: 0.7500
Epoch 23/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0121 - acc: 1.0000 2/14 [===>..........................] - ETA: 4s - loss: 0.0246 - acc: 0.9844 3/14 [=====>........................] - ETA: 3s - loss: 0.0234 - acc: 0.9896 4/14 [=======>......................] - ETA: 4s - loss: 0.0273 - acc: 0.9922 5/14 [=========>....................] - ETA: 4s - loss: 0.0323 - acc: 0.9875 6/14 [===========>..................] - ETA: 4s - loss: 0.0368 - acc: 0.9844 7/14 [==============>...............] - ETA: 3s - loss: 0.0790 - acc: 0.9662 8/14 [================>.............] - ETA: 3s - loss: 0.0709 - acc: 0.9704 9/14 [==================>...........] - ETA: 2s - loss: 0.0654 - acc: 0.973710/14 [====================>.........] - ETA: 2s - loss: 0.0616 - acc: 0.976311/14 [======================>.......] - ETA: 1s - loss: 0.0591 - acc: 0.978512/14 [========================>.....] - ETA: 1s - loss: 0.0701 - acc: 0.972513/14 [==========================>...] - ETA: 0s - loss: 0.0691 - acc: 0.9722Epoch 00022: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0679 - acc: 0.9724 - val_loss: 1.3149 - val_acc: 0.7083
Epoch 24/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0051 - acc: 1.0000 2/14 [===>..........................] - ETA: 4s - loss: 0.0398 - acc: 0.9844 3/14 [=====>........................] - ETA: 3s - loss: 0.0608 - acc: 0.9792 4/14 [=======>......................] - ETA: 4s - loss: 0.0489 - acc: 0.9844 5/14 [=========>....................] - ETA: 4s - loss: 0.0511 - acc: 0.9750 6/14 [===========>..................] - ETA: 4s - loss: 0.0579 - acc: 0.9688 7/14 [==============>...............] - ETA: 4s - loss: 0.0528 - acc: 0.9732 8/14 [================>.............] - ETA: 3s - loss: 0.0559 - acc: 0.9766 9/14 [==================>...........] - ETA: 2s - loss: 0.0547 - acc: 0.975710/14 [====================>.........] - ETA: 2s - loss: 0.0616 - acc: 0.975011/14 [======================>.......] - ETA: 1s - loss: 0.0611 - acc: 0.977312/14 [========================>.....] - ETA: 1s - loss: 0.0576 - acc: 0.979213/14 [==========================>...] - ETA: 0s - loss: 0.0551 - acc: 0.9808Epoch 00023: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0538 - acc: 0.9821 - val_loss: 1.0564 - val_acc: 0.7500
Epoch 25/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0872 - acc: 0.9688 2/14 [===>..........................] - ETA: 4s - loss: 0.0476 - acc: 0.9844 3/14 [=====>........................] - ETA: 3s - loss: 0.0925 - acc: 0.9792 4/14 [=======>......................] - ETA: 4s - loss: 0.0787 - acc: 0.9844 5/14 [=========>....................] - ETA: 4s - loss: 0.1010 - acc: 0.9750 6/14 [===========>..................] - ETA: 4s - loss: 0.0893 - acc: 0.9792 7/14 [==============>...............] - ETA: 4s - loss: 0.0864 - acc: 0.9732 8/14 [================>.............] - ETA: 3s - loss: 0.0767 - acc: 0.9766 9/14 [==================>...........] - ETA: 2s - loss: 0.0737 - acc: 0.979210/14 [====================>.........] - ETA: 2s - loss: 0.0676 - acc: 0.981211/14 [======================>.......] - ETA: 1s - loss: 0.0626 - acc: 0.983012/14 [========================>.....] - ETA: 1s - loss: 0.0730 - acc: 0.981813/14 [==========================>...] - ETA: 0s - loss: 0.0677 - acc: 0.9832Epoch 00024: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0642 - acc: 0.9843 - val_loss: 1.1461 - val_acc: 0.7396
Epoch 00024: early stopping
EVALUATING MODEL
Test loss: 1.1774480193853378
Test accuracy: 0.71875
EVALUATING BEST MODEL
Test loss: 1.1546144013350108
Test accuracy: 0.6530612244897959
Fold number 2
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_2 (InputLayer)             (None, 299, 299, 3)   0                                            
____________________________________________________________________________________________________
conv2d_95 (Conv2D)               (None, 149, 149, 32)  864         input_2[0][0]                    
____________________________________________________________________________________________________
batch_normalization_95 (BatchNor (None, 149, 149, 32)  96          conv2d_95[0][0]                  
____________________________________________________________________________________________________
activation_95 (Activation)       (None, 149, 149, 32)  0           batch_normalization_95[0][0]     
____________________________________________________________________________________________________
conv2d_96 (Conv2D)               (None, 147, 147, 32)  9216        activation_95[0][0]              
____________________________________________________________________________________________________
batch_normalization_96 (BatchNor (None, 147, 147, 32)  96          conv2d_96[0][0]                  
____________________________________________________________________________________________________
activation_96 (Activation)       (None, 147, 147, 32)  0           batch_normalization_96[0][0]     
____________________________________________________________________________________________________
conv2d_97 (Conv2D)               (None, 147, 147, 64)  18432       activation_96[0][0]              
____________________________________________________________________________________________________
batch_normalization_97 (BatchNor (None, 147, 147, 64)  192         conv2d_97[0][0]                  
____________________________________________________________________________________________________
activation_97 (Activation)       (None, 147, 147, 64)  0           batch_normalization_97[0][0]     
____________________________________________________________________________________________________
max_pooling2d_5 (MaxPooling2D)   (None, 73, 73, 64)    0           activation_97[0][0]              
____________________________________________________________________________________________________
conv2d_98 (Conv2D)               (None, 73, 73, 80)    5120        max_pooling2d_5[0][0]            
____________________________________________________________________________________________________
batch_normalization_98 (BatchNor (None, 73, 73, 80)    240         conv2d_98[0][0]                  
____________________________________________________________________________________________________
activation_98 (Activation)       (None, 73, 73, 80)    0           batch_normalization_98[0][0]     
____________________________________________________________________________________________________
conv2d_99 (Conv2D)               (None, 71, 71, 192)   138240      activation_98[0][0]              
____________________________________________________________________________________________________
batch_normalization_99 (BatchNor (None, 71, 71, 192)   576         conv2d_99[0][0]                  
____________________________________________________________________________________________________
activation_99 (Activation)       (None, 71, 71, 192)   0           batch_normalization_99[0][0]     
____________________________________________________________________________________________________
max_pooling2d_6 (MaxPooling2D)   (None, 35, 35, 192)   0           activation_99[0][0]              
____________________________________________________________________________________________________
conv2d_103 (Conv2D)              (None, 35, 35, 64)    12288       max_pooling2d_6[0][0]            
____________________________________________________________________________________________________
batch_normalization_103 (BatchNo (None, 35, 35, 64)    192         conv2d_103[0][0]                 
____________________________________________________________________________________________________
activation_103 (Activation)      (None, 35, 35, 64)    0           batch_normalization_103[0][0]    
____________________________________________________________________________________________________
conv2d_101 (Conv2D)              (None, 35, 35, 48)    9216        max_pooling2d_6[0][0]            
____________________________________________________________________________________________________
conv2d_104 (Conv2D)              (None, 35, 35, 96)    55296       activation_103[0][0]             
____________________________________________________________________________________________________
batch_normalization_101 (BatchNo (None, 35, 35, 48)    144         conv2d_101[0][0]                 
____________________________________________________________________________________________________
batch_normalization_104 (BatchNo (None, 35, 35, 96)    288         conv2d_104[0][0]                 
____________________________________________________________________________________________________
activation_101 (Activation)      (None, 35, 35, 48)    0           batch_normalization_101[0][0]    
____________________________________________________________________________________________________
activation_104 (Activation)      (None, 35, 35, 96)    0           batch_normalization_104[0][0]    
____________________________________________________________________________________________________
average_pooling2d_10 (AveragePoo (None, 35, 35, 192)   0           max_pooling2d_6[0][0]            
____________________________________________________________________________________________________
conv2d_100 (Conv2D)              (None, 35, 35, 64)    12288       max_pooling2d_6[0][0]            
____________________________________________________________________________________________________
conv2d_102 (Conv2D)              (None, 35, 35, 64)    76800       activation_101[0][0]             
____________________________________________________________________________________________________
conv2d_105 (Conv2D)              (None, 35, 35, 96)    82944       activation_104[0][0]             
____________________________________________________________________________________________________
conv2d_106 (Conv2D)              (None, 35, 35, 32)    6144        average_pooling2d_10[0][0]       
____________________________________________________________________________________________________
batch_normalization_100 (BatchNo (None, 35, 35, 64)    192         conv2d_100[0][0]                 
____________________________________________________________________________________________________
batch_normalization_102 (BatchNo (None, 35, 35, 64)    192         conv2d_102[0][0]                 
____________________________________________________________________________________________________
batch_normalization_105 (BatchNo (None, 35, 35, 96)    288         conv2d_105[0][0]                 
____________________________________________________________________________________________________
batch_normalization_106 (BatchNo (None, 35, 35, 32)    96          conv2d_106[0][0]                 
____________________________________________________________________________________________________
activation_100 (Activation)      (None, 35, 35, 64)    0           batch_normalization_100[0][0]    
____________________________________________________________________________________________________
activation_102 (Activation)      (None, 35, 35, 64)    0           batch_normalization_102[0][0]    
____________________________________________________________________________________________________
activation_105 (Activation)      (None, 35, 35, 96)    0           batch_normalization_105[0][0]    
____________________________________________________________________________________________________
activation_106 (Activation)      (None, 35, 35, 32)    0           batch_normalization_106[0][0]    
____________________________________________________________________________________________________
mixed0 (Concatenate)             (None, 35, 35, 256)   0           activation_100[0][0]             
                                                                   activation_102[0][0]             
                                                                   activation_105[0][0]             
                                                                   activation_106[0][0]             
____________________________________________________________________________________________________
conv2d_110 (Conv2D)              (None, 35, 35, 64)    16384       mixed0[0][0]                     
____________________________________________________________________________________________________
batch_normalization_110 (BatchNo (None, 35, 35, 64)    192         conv2d_110[0][0]                 
____________________________________________________________________________________________________
activation_110 (Activation)      (None, 35, 35, 64)    0           batch_normalization_110[0][0]    
____________________________________________________________________________________________________
conv2d_108 (Conv2D)              (None, 35, 35, 48)    12288       mixed0[0][0]                     
____________________________________________________________________________________________________
conv2d_111 (Conv2D)              (None, 35, 35, 96)    55296       activation_110[0][0]             
____________________________________________________________________________________________________
batch_normalization_108 (BatchNo (None, 35, 35, 48)    144         conv2d_108[0][0]                 
____________________________________________________________________________________________________
batch_normalization_111 (BatchNo (None, 35, 35, 96)    288         conv2d_111[0][0]                 
____________________________________________________________________________________________________
activation_108 (Activation)      (None, 35, 35, 48)    0           batch_normalization_108[0][0]    
____________________________________________________________________________________________________
activation_111 (Activation)      (None, 35, 35, 96)    0           batch_normalization_111[0][0]    
____________________________________________________________________________________________________
average_pooling2d_11 (AveragePoo (None, 35, 35, 256)   0           mixed0[0][0]                     
____________________________________________________________________________________________________
conv2d_107 (Conv2D)              (None, 35, 35, 64)    16384       mixed0[0][0]                     
____________________________________________________________________________________________________
conv2d_109 (Conv2D)              (None, 35, 35, 64)    76800       activation_108[0][0]             
____________________________________________________________________________________________________
conv2d_112 (Conv2D)              (None, 35, 35, 96)    82944       activation_111[0][0]             
____________________________________________________________________________________________________
conv2d_113 (Conv2D)              (None, 35, 35, 64)    16384       average_pooling2d_11[0][0]       
____________________________________________________________________________________________________
batch_normalization_107 (BatchNo (None, 35, 35, 64)    192         conv2d_107[0][0]                 
____________________________________________________________________________________________________
batch_normalization_109 (BatchNo (None, 35, 35, 64)    192         conv2d_109[0][0]                 
____________________________________________________________________________________________________
batch_normalization_112 (BatchNo (None, 35, 35, 96)    288         conv2d_112[0][0]                 
____________________________________________________________________________________________________
batch_normalization_113 (BatchNo (None, 35, 35, 64)    192         conv2d_113[0][0]                 
____________________________________________________________________________________________________
activation_107 (Activation)      (None, 35, 35, 64)    0           batch_normalization_107[0][0]    
____________________________________________________________________________________________________
activation_109 (Activation)      (None, 35, 35, 64)    0           batch_normalization_109[0][0]    
____________________________________________________________________________________________________
activation_112 (Activation)      (None, 35, 35, 96)    0           batch_normalization_112[0][0]    
____________________________________________________________________________________________________
activation_113 (Activation)      (None, 35, 35, 64)    0           batch_normalization_113[0][0]    
____________________________________________________________________________________________________
mixed1 (Concatenate)             (None, 35, 35, 288)   0           activation_107[0][0]             
                                                                   activation_109[0][0]             
                                                                   activation_112[0][0]             
                                                                   activation_113[0][0]             
____________________________________________________________________________________________________
conv2d_117 (Conv2D)              (None, 35, 35, 64)    18432       mixed1[0][0]                     
____________________________________________________________________________________________________
batch_normalization_117 (BatchNo (None, 35, 35, 64)    192         conv2d_117[0][0]                 
____________________________________________________________________________________________________
activation_117 (Activation)      (None, 35, 35, 64)    0           batch_normalization_117[0][0]    
____________________________________________________________________________________________________
conv2d_115 (Conv2D)              (None, 35, 35, 48)    13824       mixed1[0][0]                     
____________________________________________________________________________________________________
conv2d_118 (Conv2D)              (None, 35, 35, 96)    55296       activation_117[0][0]             
____________________________________________________________________________________________________
batch_normalization_115 (BatchNo (None, 35, 35, 48)    144         conv2d_115[0][0]                 
____________________________________________________________________________________________________
batch_normalization_118 (BatchNo (None, 35, 35, 96)    288         conv2d_118[0][0]                 
____________________________________________________________________________________________________
activation_115 (Activation)      (None, 35, 35, 48)    0           batch_normalization_115[0][0]    
____________________________________________________________________________________________________
activation_118 (Activation)      (None, 35, 35, 96)    0           batch_normalization_118[0][0]    
____________________________________________________________________________________________________
average_pooling2d_12 (AveragePoo (None, 35, 35, 288)   0           mixed1[0][0]                     
____________________________________________________________________________________________________
conv2d_114 (Conv2D)              (None, 35, 35, 64)    18432       mixed1[0][0]                     
____________________________________________________________________________________________________
conv2d_116 (Conv2D)              (None, 35, 35, 64)    76800       activation_115[0][0]             
____________________________________________________________________________________________________
conv2d_119 (Conv2D)              (None, 35, 35, 96)    82944       activation_118[0][0]             
____________________________________________________________________________________________________
conv2d_120 (Conv2D)              (None, 35, 35, 64)    18432       average_pooling2d_12[0][0]       
____________________________________________________________________________________________________
batch_normalization_114 (BatchNo (None, 35, 35, 64)    192         conv2d_114[0][0]                 
____________________________________________________________________________________________________
batch_normalization_116 (BatchNo (None, 35, 35, 64)    192         conv2d_116[0][0]                 
____________________________________________________________________________________________________
batch_normalization_119 (BatchNo (None, 35, 35, 96)    288         conv2d_119[0][0]                 
____________________________________________________________________________________________________
batch_normalization_120 (BatchNo (None, 35, 35, 64)    192         conv2d_120[0][0]                 
____________________________________________________________________________________________________
activation_114 (Activation)      (None, 35, 35, 64)    0           batch_normalization_114[0][0]    
____________________________________________________________________________________________________
activation_116 (Activation)      (None, 35, 35, 64)    0           batch_normalization_116[0][0]    
____________________________________________________________________________________________________
activation_119 (Activation)      (None, 35, 35, 96)    0           batch_normalization_119[0][0]    
____________________________________________________________________________________________________
activation_120 (Activation)      (None, 35, 35, 64)    0           batch_normalization_120[0][0]    
____________________________________________________________________________________________________
mixed2 (Concatenate)             (None, 35, 35, 288)   0           activation_114[0][0]             
                                                                   activation_116[0][0]             
                                                                   activation_119[0][0]             
                                                                   activation_120[0][0]             
____________________________________________________________________________________________________
conv2d_122 (Conv2D)              (None, 35, 35, 64)    18432       mixed2[0][0]                     
____________________________________________________________________________________________________
batch_normalization_122 (BatchNo (None, 35, 35, 64)    192         conv2d_122[0][0]                 
____________________________________________________________________________________________________
activation_122 (Activation)      (None, 35, 35, 64)    0           batch_normalization_122[0][0]    
____________________________________________________________________________________________________
conv2d_123 (Conv2D)              (None, 35, 35, 96)    55296       activation_122[0][0]             
____________________________________________________________________________________________________
batch_normalization_123 (BatchNo (None, 35, 35, 96)    288         conv2d_123[0][0]                 
____________________________________________________________________________________________________
activation_123 (Activation)      (None, 35, 35, 96)    0           batch_normalization_123[0][0]    
____________________________________________________________________________________________________
conv2d_121 (Conv2D)              (None, 17, 17, 384)   995328      mixed2[0][0]                     
____________________________________________________________________________________________________
conv2d_124 (Conv2D)              (None, 17, 17, 96)    82944       activation_123[0][0]             
____________________________________________________________________________________________________
batch_normalization_121 (BatchNo (None, 17, 17, 384)   1152        conv2d_121[0][0]                 
____________________________________________________________________________________________________
batch_normalization_124 (BatchNo (None, 17, 17, 96)    288         conv2d_124[0][0]                 
____________________________________________________________________________________________________
activation_121 (Activation)      (None, 17, 17, 384)   0           batch_normalization_121[0][0]    
____________________________________________________________________________________________________
activation_124 (Activation)      (None, 17, 17, 96)    0           batch_normalization_124[0][0]    
____________________________________________________________________________________________________
max_pooling2d_7 (MaxPooling2D)   (None, 17, 17, 288)   0           mixed2[0][0]                     
____________________________________________________________________________________________________
mixed3 (Concatenate)             (None, 17, 17, 768)   0           activation_121[0][0]             
                                                                   activation_124[0][0]             
                                                                   max_pooling2d_7[0][0]            
____________________________________________________________________________________________________
conv2d_129 (Conv2D)              (None, 17, 17, 128)   98304       mixed3[0][0]                     
____________________________________________________________________________________________________
batch_normalization_129 (BatchNo (None, 17, 17, 128)   384         conv2d_129[0][0]                 
____________________________________________________________________________________________________
activation_129 (Activation)      (None, 17, 17, 128)   0           batch_normalization_129[0][0]    
____________________________________________________________________________________________________
conv2d_130 (Conv2D)              (None, 17, 17, 128)   114688      activation_129[0][0]             
____________________________________________________________________________________________________
batch_normalization_130 (BatchNo (None, 17, 17, 128)   384         conv2d_130[0][0]                 
____________________________________________________________________________________________________
activation_130 (Activation)      (None, 17, 17, 128)   0           batch_normalization_130[0][0]    
____________________________________________________________________________________________________
conv2d_126 (Conv2D)              (None, 17, 17, 128)   98304       mixed3[0][0]                     
____________________________________________________________________________________________________
conv2d_131 (Conv2D)              (None, 17, 17, 128)   114688      activation_130[0][0]             
____________________________________________________________________________________________________
batch_normalization_126 (BatchNo (None, 17, 17, 128)   384         conv2d_126[0][0]                 
____________________________________________________________________________________________________
batch_normalization_131 (BatchNo (None, 17, 17, 128)   384         conv2d_131[0][0]                 
____________________________________________________________________________________________________
activation_126 (Activation)      (None, 17, 17, 128)   0           batch_normalization_126[0][0]    
____________________________________________________________________________________________________
activation_131 (Activation)      (None, 17, 17, 128)   0           batch_normalization_131[0][0]    
____________________________________________________________________________________________________
conv2d_127 (Conv2D)              (None, 17, 17, 128)   114688      activation_126[0][0]             
____________________________________________________________________________________________________
conv2d_132 (Conv2D)              (None, 17, 17, 128)   114688      activation_131[0][0]             
____________________________________________________________________________________________________
batch_normalization_127 (BatchNo (None, 17, 17, 128)   384         conv2d_127[0][0]                 
____________________________________________________________________________________________________
batch_normalization_132 (BatchNo (None, 17, 17, 128)   384         conv2d_132[0][0]                 
____________________________________________________________________________________________________
activation_127 (Activation)      (None, 17, 17, 128)   0           batch_normalization_127[0][0]    
____________________________________________________________________________________________________
activation_132 (Activation)      (None, 17, 17, 128)   0           batch_normalization_132[0][0]    
____________________________________________________________________________________________________
average_pooling2d_13 (AveragePoo (None, 17, 17, 768)   0           mixed3[0][0]                     
____________________________________________________________________________________________________
conv2d_125 (Conv2D)              (None, 17, 17, 192)   147456      mixed3[0][0]                     
____________________________________________________________________________________________________
conv2d_128 (Conv2D)              (None, 17, 17, 192)   172032      activation_127[0][0]             
____________________________________________________________________________________________________
conv2d_133 (Conv2D)              (None, 17, 17, 192)   172032      activation_132[0][0]             
____________________________________________________________________________________________________
conv2d_134 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_13[0][0]       
____________________________________________________________________________________________________
batch_normalization_125 (BatchNo (None, 17, 17, 192)   576         conv2d_125[0][0]                 
____________________________________________________________________________________________________
batch_normalization_128 (BatchNo (None, 17, 17, 192)   576         conv2d_128[0][0]                 
____________________________________________________________________________________________________
batch_normalization_133 (BatchNo (None, 17, 17, 192)   576         conv2d_133[0][0]                 
____________________________________________________________________________________________________
batch_normalization_134 (BatchNo (None, 17, 17, 192)   576         conv2d_134[0][0]                 
____________________________________________________________________________________________________
activation_125 (Activation)      (None, 17, 17, 192)   0           batch_normalization_125[0][0]    
____________________________________________________________________________________________________
activation_128 (Activation)      (None, 17, 17, 192)   0           batch_normalization_128[0][0]    
____________________________________________________________________________________________________
activation_133 (Activation)      (None, 17, 17, 192)   0           batch_normalization_133[0][0]    
____________________________________________________________________________________________________
activation_134 (Activation)      (None, 17, 17, 192)   0           batch_normalization_134[0][0]    
____________________________________________________________________________________________________
mixed4 (Concatenate)             (None, 17, 17, 768)   0           activation_125[0][0]             
                                                                   activation_128[0][0]             
                                                                   activation_133[0][0]             
                                                                   activation_134[0][0]             
____________________________________________________________________________________________________
conv2d_139 (Conv2D)              (None, 17, 17, 160)   122880      mixed4[0][0]                     
____________________________________________________________________________________________________
batch_normalization_139 (BatchNo (None, 17, 17, 160)   480         conv2d_139[0][0]                 
____________________________________________________________________________________________________
activation_139 (Activation)      (None, 17, 17, 160)   0           batch_normalization_139[0][0]    
____________________________________________________________________________________________________
conv2d_140 (Conv2D)              (None, 17, 17, 160)   179200      activation_139[0][0]             
____________________________________________________________________________________________________
batch_normalization_140 (BatchNo (None, 17, 17, 160)   480         conv2d_140[0][0]                 
____________________________________________________________________________________________________
activation_140 (Activation)      (None, 17, 17, 160)   0           batch_normalization_140[0][0]    
____________________________________________________________________________________________________
conv2d_136 (Conv2D)              (None, 17, 17, 160)   122880      mixed4[0][0]                     
____________________________________________________________________________________________________
conv2d_141 (Conv2D)              (None, 17, 17, 160)   179200      activation_140[0][0]             
____________________________________________________________________________________________________
batch_normalization_136 (BatchNo (None, 17, 17, 160)   480         conv2d_136[0][0]                 
____________________________________________________________________________________________________
batch_normalization_141 (BatchNo (None, 17, 17, 160)   480         conv2d_141[0][0]                 
____________________________________________________________________________________________________
activation_136 (Activation)      (None, 17, 17, 160)   0           batch_normalization_136[0][0]    
____________________________________________________________________________________________________
activation_141 (Activation)      (None, 17, 17, 160)   0           batch_normalization_141[0][0]    
____________________________________________________________________________________________________
conv2d_137 (Conv2D)              (None, 17, 17, 160)   179200      activation_136[0][0]             
____________________________________________________________________________________________________
conv2d_142 (Conv2D)              (None, 17, 17, 160)   179200      activation_141[0][0]             
____________________________________________________________________________________________________
batch_normalization_137 (BatchNo (None, 17, 17, 160)   480         conv2d_137[0][0]                 
____________________________________________________________________________________________________
batch_normalization_142 (BatchNo (None, 17, 17, 160)   480         conv2d_142[0][0]                 
____________________________________________________________________________________________________
activation_137 (Activation)      (None, 17, 17, 160)   0           batch_normalization_137[0][0]    
____________________________________________________________________________________________________
activation_142 (Activation)      (None, 17, 17, 160)   0           batch_normalization_142[0][0]    
____________________________________________________________________________________________________
average_pooling2d_14 (AveragePoo (None, 17, 17, 768)   0           mixed4[0][0]                     
____________________________________________________________________________________________________
conv2d_135 (Conv2D)              (None, 17, 17, 192)   147456      mixed4[0][0]                     
____________________________________________________________________________________________________
conv2d_138 (Conv2D)              (None, 17, 17, 192)   215040      activation_137[0][0]             
____________________________________________________________________________________________________
conv2d_143 (Conv2D)              (None, 17, 17, 192)   215040      activation_142[0][0]             
____________________________________________________________________________________________________
conv2d_144 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_14[0][0]       
____________________________________________________________________________________________________
batch_normalization_135 (BatchNo (None, 17, 17, 192)   576         conv2d_135[0][0]                 
____________________________________________________________________________________________________
batch_normalization_138 (BatchNo (None, 17, 17, 192)   576         conv2d_138[0][0]                 
____________________________________________________________________________________________________
batch_normalization_143 (BatchNo (None, 17, 17, 192)   576         conv2d_143[0][0]                 
____________________________________________________________________________________________________
batch_normalization_144 (BatchNo (None, 17, 17, 192)   576         conv2d_144[0][0]                 
____________________________________________________________________________________________________
activation_135 (Activation)      (None, 17, 17, 192)   0           batch_normalization_135[0][0]    
____________________________________________________________________________________________________
activation_138 (Activation)      (None, 17, 17, 192)   0           batch_normalization_138[0][0]    
____________________________________________________________________________________________________
activation_143 (Activation)      (None, 17, 17, 192)   0           batch_normalization_143[0][0]    
____________________________________________________________________________________________________
activation_144 (Activation)      (None, 17, 17, 192)   0           batch_normalization_144[0][0]    
____________________________________________________________________________________________________
mixed5 (Concatenate)             (None, 17, 17, 768)   0           activation_135[0][0]             
                                                                   activation_138[0][0]             
                                                                   activation_143[0][0]             
                                                                   activation_144[0][0]             
____________________________________________________________________________________________________
conv2d_149 (Conv2D)              (None, 17, 17, 160)   122880      mixed5[0][0]                     
____________________________________________________________________________________________________
batch_normalization_149 (BatchNo (None, 17, 17, 160)   480         conv2d_149[0][0]                 
____________________________________________________________________________________________________
activation_149 (Activation)      (None, 17, 17, 160)   0           batch_normalization_149[0][0]    
____________________________________________________________________________________________________
conv2d_150 (Conv2D)              (None, 17, 17, 160)   179200      activation_149[0][0]             
____________________________________________________________________________________________________
batch_normalization_150 (BatchNo (None, 17, 17, 160)   480         conv2d_150[0][0]                 
____________________________________________________________________________________________________
activation_150 (Activation)      (None, 17, 17, 160)   0           batch_normalization_150[0][0]    
____________________________________________________________________________________________________
conv2d_146 (Conv2D)              (None, 17, 17, 160)   122880      mixed5[0][0]                     
____________________________________________________________________________________________________
conv2d_151 (Conv2D)              (None, 17, 17, 160)   179200      activation_150[0][0]             
____________________________________________________________________________________________________
batch_normalization_146 (BatchNo (None, 17, 17, 160)   480         conv2d_146[0][0]                 
____________________________________________________________________________________________________
batch_normalization_151 (BatchNo (None, 17, 17, 160)   480         conv2d_151[0][0]                 
____________________________________________________________________________________________________
activation_146 (Activation)      (None, 17, 17, 160)   0           batch_normalization_146[0][0]    
____________________________________________________________________________________________________
activation_151 (Activation)      (None, 17, 17, 160)   0           batch_normalization_151[0][0]    
____________________________________________________________________________________________________
conv2d_147 (Conv2D)              (None, 17, 17, 160)   179200      activation_146[0][0]             
____________________________________________________________________________________________________
conv2d_152 (Conv2D)              (None, 17, 17, 160)   179200      activation_151[0][0]             
____________________________________________________________________________________________________
batch_normalization_147 (BatchNo (None, 17, 17, 160)   480         conv2d_147[0][0]                 
____________________________________________________________________________________________________
batch_normalization_152 (BatchNo (None, 17, 17, 160)   480         conv2d_152[0][0]                 
____________________________________________________________________________________________________
activation_147 (Activation)      (None, 17, 17, 160)   0           batch_normalization_147[0][0]    
____________________________________________________________________________________________________
activation_152 (Activation)      (None, 17, 17, 160)   0           batch_normalization_152[0][0]    
____________________________________________________________________________________________________
average_pooling2d_15 (AveragePoo (None, 17, 17, 768)   0           mixed5[0][0]                     
____________________________________________________________________________________________________
conv2d_145 (Conv2D)              (None, 17, 17, 192)   147456      mixed5[0][0]                     
____________________________________________________________________________________________________
conv2d_148 (Conv2D)              (None, 17, 17, 192)   215040      activation_147[0][0]             
____________________________________________________________________________________________________
conv2d_153 (Conv2D)              (None, 17, 17, 192)   215040      activation_152[0][0]             
____________________________________________________________________________________________________
conv2d_154 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_15[0][0]       
____________________________________________________________________________________________________
batch_normalization_145 (BatchNo (None, 17, 17, 192)   576         conv2d_145[0][0]                 
____________________________________________________________________________________________________
batch_normalization_148 (BatchNo (None, 17, 17, 192)   576         conv2d_148[0][0]                 
____________________________________________________________________________________________________
batch_normalization_153 (BatchNo (None, 17, 17, 192)   576         conv2d_153[0][0]                 
____________________________________________________________________________________________________
batch_normalization_154 (BatchNo (None, 17, 17, 192)   576         conv2d_154[0][0]                 
____________________________________________________________________________________________________
activation_145 (Activation)      (None, 17, 17, 192)   0           batch_normalization_145[0][0]    
____________________________________________________________________________________________________
activation_148 (Activation)      (None, 17, 17, 192)   0           batch_normalization_148[0][0]    
____________________________________________________________________________________________________
activation_153 (Activation)      (None, 17, 17, 192)   0           batch_normalization_153[0][0]    
____________________________________________________________________________________________________
activation_154 (Activation)      (None, 17, 17, 192)   0           batch_normalization_154[0][0]    
____________________________________________________________________________________________________
mixed6 (Concatenate)             (None, 17, 17, 768)   0           activation_145[0][0]             
                                                                   activation_148[0][0]             
                                                                   activation_153[0][0]             
                                                                   activation_154[0][0]             
____________________________________________________________________________________________________
conv2d_159 (Conv2D)              (None, 17, 17, 192)   147456      mixed6[0][0]                     
____________________________________________________________________________________________________
batch_normalization_159 (BatchNo (None, 17, 17, 192)   576         conv2d_159[0][0]                 
____________________________________________________________________________________________________
activation_159 (Activation)      (None, 17, 17, 192)   0           batch_normalization_159[0][0]    
____________________________________________________________________________________________________
conv2d_160 (Conv2D)              (None, 17, 17, 192)   258048      activation_159[0][0]             
____________________________________________________________________________________________________
batch_normalization_160 (BatchNo (None, 17, 17, 192)   576         conv2d_160[0][0]                 
____________________________________________________________________________________________________
activation_160 (Activation)      (None, 17, 17, 192)   0           batch_normalization_160[0][0]    
____________________________________________________________________________________________________
conv2d_156 (Conv2D)              (None, 17, 17, 192)   147456      mixed6[0][0]                     
____________________________________________________________________________________________________
conv2d_161 (Conv2D)              (None, 17, 17, 192)   258048      activation_160[0][0]             
____________________________________________________________________________________________________
batch_normalization_156 (BatchNo (None, 17, 17, 192)   576         conv2d_156[0][0]                 
____________________________________________________________________________________________________
batch_normalization_161 (BatchNo (None, 17, 17, 192)   576         conv2d_161[0][0]                 
____________________________________________________________________________________________________
activation_156 (Activation)      (None, 17, 17, 192)   0           batch_normalization_156[0][0]    
____________________________________________________________________________________________________
activation_161 (Activation)      (None, 17, 17, 192)   0           batch_normalization_161[0][0]    
____________________________________________________________________________________________________
conv2d_157 (Conv2D)              (None, 17, 17, 192)   258048      activation_156[0][0]             
____________________________________________________________________________________________________
conv2d_162 (Conv2D)              (None, 17, 17, 192)   258048      activation_161[0][0]             
____________________________________________________________________________________________________
batch_normalization_157 (BatchNo (None, 17, 17, 192)   576         conv2d_157[0][0]                 
____________________________________________________________________________________________________
batch_normalization_162 (BatchNo (None, 17, 17, 192)   576         conv2d_162[0][0]                 
____________________________________________________________________________________________________
activation_157 (Activation)      (None, 17, 17, 192)   0           batch_normalization_157[0][0]    
____________________________________________________________________________________________________
activation_162 (Activation)      (None, 17, 17, 192)   0           batch_normalization_162[0][0]    
____________________________________________________________________________________________________
average_pooling2d_16 (AveragePoo (None, 17, 17, 768)   0           mixed6[0][0]                     
____________________________________________________________________________________________________
conv2d_155 (Conv2D)              (None, 17, 17, 192)   147456      mixed6[0][0]                     
____________________________________________________________________________________________________
conv2d_158 (Conv2D)              (None, 17, 17, 192)   258048      activation_157[0][0]             
____________________________________________________________________________________________________
conv2d_163 (Conv2D)              (None, 17, 17, 192)   258048      activation_162[0][0]             
____________________________________________________________________________________________________
conv2d_164 (Conv2D)              (None, 17, 17, 192)   147456      average_pooling2d_16[0][0]       
____________________________________________________________________________________________________
batch_normalization_155 (BatchNo (None, 17, 17, 192)   576         conv2d_155[0][0]                 
____________________________________________________________________________________________________
batch_normalization_158 (BatchNo (None, 17, 17, 192)   576         conv2d_158[0][0]                 
____________________________________________________________________________________________________
batch_normalization_163 (BatchNo (None, 17, 17, 192)   576         conv2d_163[0][0]                 
____________________________________________________________________________________________________
batch_normalization_164 (BatchNo (None, 17, 17, 192)   576         conv2d_164[0][0]                 
____________________________________________________________________________________________________
activation_155 (Activation)      (None, 17, 17, 192)   0           batch_normalization_155[0][0]    
____________________________________________________________________________________________________
activation_158 (Activation)      (None, 17, 17, 192)   0           batch_normalization_158[0][0]    
____________________________________________________________________________________________________
activation_163 (Activation)      (None, 17, 17, 192)   0           batch_normalization_163[0][0]    
____________________________________________________________________________________________________
activation_164 (Activation)      (None, 17, 17, 192)   0           batch_normalization_164[0][0]    
____________________________________________________________________________________________________
mixed7 (Concatenate)             (None, 17, 17, 768)   0           activation_155[0][0]             
                                                                   activation_158[0][0]             
                                                                   activation_163[0][0]             
                                                                   activation_164[0][0]             
____________________________________________________________________________________________________
conv2d_167 (Conv2D)              (None, 17, 17, 192)   147456      mixed7[0][0]                     
____________________________________________________________________________________________________
batch_normalization_167 (BatchNo (None, 17, 17, 192)   576         conv2d_167[0][0]                 
____________________________________________________________________________________________________
activation_167 (Activation)      (None, 17, 17, 192)   0           batch_normalization_167[0][0]    
____________________________________________________________________________________________________
conv2d_168 (Conv2D)              (None, 17, 17, 192)   258048      activation_167[0][0]             
____________________________________________________________________________________________________
batch_normalization_168 (BatchNo (None, 17, 17, 192)   576         conv2d_168[0][0]                 
____________________________________________________________________________________________________
activation_168 (Activation)      (None, 17, 17, 192)   0           batch_normalization_168[0][0]    
____________________________________________________________________________________________________
conv2d_165 (Conv2D)              (None, 17, 17, 192)   147456      mixed7[0][0]                     
____________________________________________________________________________________________________
conv2d_169 (Conv2D)              (None, 17, 17, 192)   258048      activation_168[0][0]             
____________________________________________________________________________________________________
batch_normalization_165 (BatchNo (None, 17, 17, 192)   576         conv2d_165[0][0]                 
____________________________________________________________________________________________________
batch_normalization_169 (BatchNo (None, 17, 17, 192)   576         conv2d_169[0][0]                 
____________________________________________________________________________________________________
activation_165 (Activation)      (None, 17, 17, 192)   0           batch_normalization_165[0][0]    
____________________________________________________________________________________________________
activation_169 (Activation)      (None, 17, 17, 192)   0           batch_normalization_169[0][0]    
____________________________________________________________________________________________________
conv2d_166 (Conv2D)              (None, 8, 8, 320)     552960      activation_165[0][0]             
____________________________________________________________________________________________________
conv2d_170 (Conv2D)              (None, 8, 8, 192)     331776      activation_169[0][0]             
____________________________________________________________________________________________________
batch_normalization_166 (BatchNo (None, 8, 8, 320)     960         conv2d_166[0][0]                 
____________________________________________________________________________________________________
batch_normalization_170 (BatchNo (None, 8, 8, 192)     576         conv2d_170[0][0]                 
____________________________________________________________________________________________________
activation_166 (Activation)      (None, 8, 8, 320)     0           batch_normalization_166[0][0]    
____________________________________________________________________________________________________
activation_170 (Activation)      (None, 8, 8, 192)     0           batch_normalization_170[0][0]    
____________________________________________________________________________________________________
max_pooling2d_8 (MaxPooling2D)   (None, 8, 8, 768)     0           mixed7[0][0]                     
____________________________________________________________________________________________________
mixed8 (Concatenate)             (None, 8, 8, 1280)    0           activation_166[0][0]             
                                                                   activation_170[0][0]             
                                                                   max_pooling2d_8[0][0]            
____________________________________________________________________________________________________
conv2d_175 (Conv2D)              (None, 8, 8, 448)     573440      mixed8[0][0]                     
____________________________________________________________________________________________________
batch_normalization_175 (BatchNo (None, 8, 8, 448)     1344        conv2d_175[0][0]                 
____________________________________________________________________________________________________
activation_175 (Activation)      (None, 8, 8, 448)     0           batch_normalization_175[0][0]    
____________________________________________________________________________________________________
conv2d_172 (Conv2D)              (None, 8, 8, 384)     491520      mixed8[0][0]                     
____________________________________________________________________________________________________
conv2d_176 (Conv2D)              (None, 8, 8, 384)     1548288     activation_175[0][0]             
____________________________________________________________________________________________________
batch_normalization_172 (BatchNo (None, 8, 8, 384)     1152        conv2d_172[0][0]                 
____________________________________________________________________________________________________
batch_normalization_176 (BatchNo (None, 8, 8, 384)     1152        conv2d_176[0][0]                 
____________________________________________________________________________________________________
activation_172 (Activation)      (None, 8, 8, 384)     0           batch_normalization_172[0][0]    
____________________________________________________________________________________________________
activation_176 (Activation)      (None, 8, 8, 384)     0           batch_normalization_176[0][0]    
____________________________________________________________________________________________________
conv2d_173 (Conv2D)              (None, 8, 8, 384)     442368      activation_172[0][0]             
____________________________________________________________________________________________________
conv2d_174 (Conv2D)              (None, 8, 8, 384)     442368      activation_172[0][0]             
____________________________________________________________________________________________________
conv2d_177 (Conv2D)              (None, 8, 8, 384)     442368      activation_176[0][0]             
____________________________________________________________________________________________________
conv2d_178 (Conv2D)              (None, 8, 8, 384)     442368      activation_176[0][0]             
____________________________________________________________________________________________________
average_pooling2d_17 (AveragePoo (None, 8, 8, 1280)    0           mixed8[0][0]                     
____________________________________________________________________________________________________
conv2d_171 (Conv2D)              (None, 8, 8, 320)     409600      mixed8[0][0]                     
____________________________________________________________________________________________________
batch_normalization_173 (BatchNo (None, 8, 8, 384)     1152        conv2d_173[0][0]                 
____________________________________________________________________________________________________
batch_normalization_174 (BatchNo (None, 8, 8, 384)     1152        conv2d_174[0][0]                 
____________________________________________________________________________________________________
batch_normalization_177 (BatchNo (None, 8, 8, 384)     1152        conv2d_177[0][0]                 
____________________________________________________________________________________________________
batch_normalization_178 (BatchNo (None, 8, 8, 384)     1152        conv2d_178[0][0]                 
____________________________________________________________________________________________________
conv2d_179 (Conv2D)              (None, 8, 8, 192)     245760      average_pooling2d_17[0][0]       
____________________________________________________________________________________________________
batch_normalization_171 (BatchNo (None, 8, 8, 320)     960         conv2d_171[0][0]                 
____________________________________________________________________________________________________
activation_173 (Activation)      (None, 8, 8, 384)     0           batch_normalization_173[0][0]    
____________________________________________________________________________________________________
activation_174 (Activation)      (None, 8, 8, 384)     0           batch_normalization_174[0][0]    
____________________________________________________________________________________________________
activation_177 (Activation)      (None, 8, 8, 384)     0           batch_normalization_177[0][0]    
____________________________________________________________________________________________________
activation_178 (Activation)      (None, 8, 8, 384)     0           batch_normalization_178[0][0]    
____________________________________________________________________________________________________
batch_normalization_179 (BatchNo (None, 8, 8, 192)     576         conv2d_179[0][0]                 
____________________________________________________________________________________________________
activation_171 (Activation)      (None, 8, 8, 320)     0           batch_normalization_171[0][0]    
____________________________________________________________________________________________________
mixed9_0 (Concatenate)           (None, 8, 8, 768)     0           activation_173[0][0]             
                                                                   activation_174[0][0]             
____________________________________________________________________________________________________
concatenate_3 (Concatenate)      (None, 8, 8, 768)     0           activation_177[0][0]             
                                                                   activation_178[0][0]             
____________________________________________________________________________________________________
activation_179 (Activation)      (None, 8, 8, 192)     0           batch_normalization_179[0][0]    
____________________________________________________________________________________________________
mixed9 (Concatenate)             (None, 8, 8, 2048)    0           activation_171[0][0]             
                                                                   mixed9_0[0][0]                   
                                                                   concatenate_3[0][0]              
                                                                   activation_179[0][0]             
____________________________________________________________________________________________________
conv2d_184 (Conv2D)              (None, 8, 8, 448)     917504      mixed9[0][0]                     
____________________________________________________________________________________________________
batch_normalization_184 (BatchNo (None, 8, 8, 448)     1344        conv2d_184[0][0]                 
____________________________________________________________________________________________________
activation_184 (Activation)      (None, 8, 8, 448)     0           batch_normalization_184[0][0]    
____________________________________________________________________________________________________
conv2d_181 (Conv2D)              (None, 8, 8, 384)     786432      mixed9[0][0]                     
____________________________________________________________________________________________________
conv2d_185 (Conv2D)              (None, 8, 8, 384)     1548288     activation_184[0][0]             
____________________________________________________________________________________________________
batch_normalization_181 (BatchNo (None, 8, 8, 384)     1152        conv2d_181[0][0]                 
____________________________________________________________________________________________________
batch_normalization_185 (BatchNo (None, 8, 8, 384)     1152        conv2d_185[0][0]                 
____________________________________________________________________________________________________
activation_181 (Activation)      (None, 8, 8, 384)     0           batch_normalization_181[0][0]    
____________________________________________________________________________________________________
activation_185 (Activation)      (None, 8, 8, 384)     0           batch_normalization_185[0][0]    
____________________________________________________________________________________________________
conv2d_182 (Conv2D)              (None, 8, 8, 384)     442368      activation_181[0][0]             
____________________________________________________________________________________________________
conv2d_183 (Conv2D)              (None, 8, 8, 384)     442368      activation_181[0][0]             
____________________________________________________________________________________________________
conv2d_186 (Conv2D)              (None, 8, 8, 384)     442368      activation_185[0][0]             
____________________________________________________________________________________________________
conv2d_187 (Conv2D)              (None, 8, 8, 384)     442368      activation_185[0][0]             
____________________________________________________________________________________________________
average_pooling2d_18 (AveragePoo (None, 8, 8, 2048)    0           mixed9[0][0]                     
____________________________________________________________________________________________________
conv2d_180 (Conv2D)              (None, 8, 8, 320)     655360      mixed9[0][0]                     
____________________________________________________________________________________________________
batch_normalization_182 (BatchNo (None, 8, 8, 384)     1152        conv2d_182[0][0]                 
____________________________________________________________________________________________________
batch_normalization_183 (BatchNo (None, 8, 8, 384)     1152        conv2d_183[0][0]                 
____________________________________________________________________________________________________
batch_normalization_186 (BatchNo (None, 8, 8, 384)     1152        conv2d_186[0][0]                 
____________________________________________________________________________________________________
batch_normalization_187 (BatchNo (None, 8, 8, 384)     1152        conv2d_187[0][0]                 
____________________________________________________________________________________________________
conv2d_188 (Conv2D)              (None, 8, 8, 192)     393216      average_pooling2d_18[0][0]       
____________________________________________________________________________________________________
batch_normalization_180 (BatchNo (None, 8, 8, 320)     960         conv2d_180[0][0]                 
____________________________________________________________________________________________________
activation_182 (Activation)      (None, 8, 8, 384)     0           batch_normalization_182[0][0]    
____________________________________________________________________________________________________
activation_183 (Activation)      (None, 8, 8, 384)     0           batch_normalization_183[0][0]    
____________________________________________________________________________________________________
activation_186 (Activation)      (None, 8, 8, 384)     0           batch_normalization_186[0][0]    
____________________________________________________________________________________________________
activation_187 (Activation)      (None, 8, 8, 384)     0           batch_normalization_187[0][0]    
____________________________________________________________________________________________________
batch_normalization_188 (BatchNo (None, 8, 8, 192)     576         conv2d_188[0][0]                 
____________________________________________________________________________________________________
activation_180 (Activation)      (None, 8, 8, 320)     0           batch_normalization_180[0][0]    
____________________________________________________________________________________________________
mixed9_1 (Concatenate)           (None, 8, 8, 768)     0           activation_182[0][0]             
                                                                   activation_183[0][0]             
____________________________________________________________________________________________________
concatenate_4 (Concatenate)      (None, 8, 8, 768)     0           activation_186[0][0]             
                                                                   activation_187[0][0]             
____________________________________________________________________________________________________
activation_188 (Activation)      (None, 8, 8, 192)     0           batch_normalization_188[0][0]    
____________________________________________________________________________________________________
mixed10 (Concatenate)            (None, 8, 8, 2048)    0           activation_180[0][0]             
                                                                   mixed9_1[0][0]                   
                                                                   concatenate_4[0][0]              
                                                                   activation_188[0][0]             
____________________________________________________________________________________________________
global_average_pooling2d_2 (Glob (None, 2048)          0           mixed10[0][0]                    
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 3)             6147        global_average_pooling2d_2[0][0] 
====================================================================================================
Total params: 21,808,931
Trainable params: 21,774,499
Non-trainable params: 34,432
____________________________________________________________________________________________________
Found 457 images belonging to 3 classes.
Found 114 images belonging to 3 classes.
Found 130 images belonging to 3 classes.
Epoch 1/150
 1/14 [=>............................] - ETA: 74s - loss: 1.1675 - acc: 0.2500 2/14 [===>..........................] - ETA: 36s - loss: 1.1233 - acc: 0.3281 3/14 [=====>........................] - ETA: 23s - loss: 1.0902 - acc: 0.3750 4/14 [=======>......................] - ETA: 16s - loss: 1.0603 - acc: 0.4141 5/14 [=========>....................] - ETA: 12s - loss: 1.0729 - acc: 0.4250 6/14 [===========>..................] - ETA: 9s - loss: 1.0770 - acc: 0.4219  7/14 [==============>...............] - ETA: 7s - loss: 1.0781 - acc: 0.4241 8/14 [================>.............] - ETA: 6s - loss: 1.0608 - acc: 0.4453 9/14 [==================>...........] - ETA: 4s - loss: 1.0531 - acc: 0.447910/14 [====================>.........] - ETA: 3s - loss: 1.0362 - acc: 0.462511/14 [======================>.......] - ETA: 2s - loss: 1.0303 - acc: 0.463112/14 [========================>.....] - ETA: 1s - loss: 1.0280 - acc: 0.468813/14 [==========================>...] - ETA: 0s - loss: 1.0424 - acc: 0.4591Epoch 00000: val_acc improved from -inf to 0.47917, saving model to /mnt/Data/ltanzi/networksForCam/Fold2_InceptionforCAMA1A2A3-best_model.h5
14/14 [==============================] - 58s - loss: 1.0259 - acc: 0.4754 - val_loss: 0.9699 - val_acc: 0.4792
Epoch 2/150
 1/14 [=>............................] - ETA: 6s - loss: 0.9118 - acc: 0.6667 2/14 [===>..........................] - ETA: 5s - loss: 0.8601 - acc: 0.6458 3/14 [=====>........................] - ETA: 4s - loss: 0.8032 - acc: 0.6493 4/14 [=======>......................] - ETA: 3s - loss: 0.7620 - acc: 0.6745 5/14 [=========>....................] - ETA: 3s - loss: 0.7378 - acc: 0.6833 6/14 [===========>..................] - ETA: 3s - loss: 0.7251 - acc: 0.6944 7/14 [==============>...............] - ETA: 2s - loss: 0.7426 - acc: 0.6845 8/14 [================>.............] - ETA: 2s - loss: 0.7314 - acc: 0.6888 9/14 [==================>...........] - ETA: 1s - loss: 0.7276 - acc: 0.681710/14 [====================>.........] - ETA: 1s - loss: 0.7200 - acc: 0.676011/14 [======================>.......] - ETA: 1s - loss: 0.7122 - acc: 0.679912/14 [========================>.....] - ETA: 0s - loss: 0.7027 - acc: 0.685813/14 [==========================>...] - ETA: 0s - loss: 0.6857 - acc: 0.6907Epoch 00001: val_acc did not improve
14/14 [==============================] - 6s - loss: 0.6662 - acc: 0.7062 - val_loss: 1.2620 - val_acc: 0.4688
Epoch 3/150
 1/14 [=>............................] - ETA: 4s - loss: 0.5672 - acc: 0.7188 2/14 [===>..........................] - ETA: 2s - loss: 0.6191 - acc: 0.6927 3/14 [=====>........................] - ETA: 2s - loss: 0.5461 - acc: 0.7535 4/14 [=======>......................] - ETA: 2s - loss: 0.5134 - acc: 0.7526 5/14 [=========>....................] - ETA: 2s - loss: 0.5061 - acc: 0.7583 6/14 [===========>..................] - ETA: 2s - loss: 0.5074 - acc: 0.7517 7/14 [==============>...............] - ETA: 2s - loss: 0.4848 - acc: 0.7783 8/14 [================>.............] - ETA: 2s - loss: 0.4958 - acc: 0.7826 9/14 [==================>...........] - ETA: 2s - loss: 0.5067 - acc: 0.772010/14 [====================>.........] - ETA: 1s - loss: 0.5043 - acc: 0.769811/14 [======================>.......] - ETA: 1s - loss: 0.4956 - acc: 0.770812/14 [========================>.....] - ETA: 1s - loss: 0.4966 - acc: 0.776913/14 [==========================>...] - ETA: 0s - loss: 0.4861 - acc: 0.7845Epoch 00002: val_acc improved from 0.47917 to 0.53125, saving model to /mnt/Data/ltanzi/networksForCam/Fold2_InceptionforCAMA1A2A3-best_model.h5
14/14 [==============================] - 11s - loss: 0.4818 - acc: 0.7869 - val_loss: 1.1359 - val_acc: 0.5312
Epoch 4/150
 1/14 [=>............................] - ETA: 4s - loss: 0.2994 - acc: 0.9062 2/14 [===>..........................] - ETA: 4s - loss: 0.2868 - acc: 0.9062 3/14 [=====>........................] - ETA: 3s - loss: 0.3795 - acc: 0.8634 4/14 [=======>......................] - ETA: 2s - loss: 0.3239 - acc: 0.8898 5/14 [=========>....................] - ETA: 3s - loss: 0.3024 - acc: 0.8931 6/14 [===========>..................] - ETA: 3s - loss: 0.3206 - acc: 0.8848 7/14 [==============>...............] - ETA: 3s - loss: 0.3022 - acc: 0.8968 8/14 [================>.............] - ETA: 3s - loss: 0.2838 - acc: 0.9058 9/14 [==================>...........] - ETA: 2s - loss: 0.3074 - acc: 0.895410/14 [====================>.........] - ETA: 2s - loss: 0.3082 - acc: 0.893411/14 [======================>.......] - ETA: 1s - loss: 0.3104 - acc: 0.891712/14 [========================>.....] - ETA: 1s - loss: 0.3095 - acc: 0.892913/14 [==========================>...] - ETA: 0s - loss: 0.3047 - acc: 0.8964Epoch 00003: val_acc improved from 0.53125 to 0.58333, saving model to /mnt/Data/ltanzi/networksForCam/Fold2_InceptionforCAMA1A2A3-best_model.h5
14/14 [==============================] - 13s - loss: 0.3042 - acc: 0.8930 - val_loss: 1.0497 - val_acc: 0.5833
Epoch 5/150
 1/14 [=>............................] - ETA: 4s - loss: 0.4445 - acc: 0.7812 2/14 [===>..........................] - ETA: 4s - loss: 0.3022 - acc: 0.8594 3/14 [=====>........................] - ETA: 3s - loss: 0.3587 - acc: 0.8333 4/14 [=======>......................] - ETA: 2s - loss: 0.4105 - acc: 0.7917 5/14 [=========>....................] - ETA: 3s - loss: 0.3439 - acc: 0.8333 6/14 [===========>..................] - ETA: 3s - loss: 0.3320 - acc: 0.8559 7/14 [==============>...............] - ETA: 3s - loss: 0.2992 - acc: 0.8676 8/14 [================>.............] - ETA: 3s - loss: 0.3002 - acc: 0.8685 9/14 [==================>...........] - ETA: 2s - loss: 0.2842 - acc: 0.876210/14 [====================>.........] - ETA: 2s - loss: 0.2775 - acc: 0.879211/14 [======================>.......] - ETA: 1s - loss: 0.2762 - acc: 0.884512/14 [========================>.....] - ETA: 1s - loss: 0.2661 - acc: 0.888913/14 [==========================>...] - ETA: 0s - loss: 0.2632 - acc: 0.8902Epoch 00004: val_acc improved from 0.58333 to 0.59375, saving model to /mnt/Data/ltanzi/networksForCam/Fold2_InceptionforCAMA1A2A3-best_model.h5
14/14 [==============================] - 12s - loss: 0.2643 - acc: 0.8922 - val_loss: 1.0686 - val_acc: 0.5938
Epoch 6/150
 1/14 [=>............................] - ETA: 4s - loss: 0.2026 - acc: 0.9688 2/14 [===>..........................] - ETA: 4s - loss: 0.1734 - acc: 0.9531 3/14 [=====>........................] - ETA: 3s - loss: 0.1765 - acc: 0.9479 4/14 [=======>......................] - ETA: 4s - loss: 0.1726 - acc: 0.9531 5/14 [=========>....................] - ETA: 3s - loss: 0.2330 - acc: 0.9181 6/14 [===========>..................] - ETA: 3s - loss: 0.2021 - acc: 0.9317 7/14 [==============>...............] - ETA: 3s - loss: 0.1916 - acc: 0.9415 8/14 [================>.............] - ETA: 3s - loss: 0.1890 - acc: 0.9410 9/14 [==================>...........] - ETA: 2s - loss: 0.1832 - acc: 0.944110/14 [====================>.........] - ETA: 2s - loss: 0.1715 - acc: 0.949711/14 [======================>.......] - ETA: 1s - loss: 0.1626 - acc: 0.954212/14 [========================>.....] - ETA: 1s - loss: 0.1569 - acc: 0.958013/14 [==========================>...] - ETA: 0s - loss: 0.1503 - acc: 0.9613Epoch 00005: val_acc improved from 0.59375 to 0.76042, saving model to /mnt/Data/ltanzi/networksForCam/Fold2_InceptionforCAMA1A2A3-best_model.h5
14/14 [==============================] - 12s - loss: 0.1483 - acc: 0.9602 - val_loss: 0.8445 - val_acc: 0.7604
Epoch 7/150
 1/14 [=>............................] - ETA: 4s - loss: 0.2933 - acc: 0.9062 2/14 [===>..........................] - ETA: 4s - loss: 0.3267 - acc: 0.9062 3/14 [=====>........................] - ETA: 3s - loss: 0.3171 - acc: 0.9062 4/14 [=======>......................] - ETA: 4s - loss: 0.2575 - acc: 0.9297 5/14 [=========>....................] - ETA: 4s - loss: 0.2282 - acc: 0.9375 6/14 [===========>..................] - ETA: 3s - loss: 0.2064 - acc: 0.9479 7/14 [==============>...............] - ETA: 3s - loss: 0.1965 - acc: 0.9464 8/14 [================>.............] - ETA: 3s - loss: 0.1906 - acc: 0.9492 9/14 [==================>...........] - ETA: 2s - loss: 0.1800 - acc: 0.951410/14 [====================>.........] - ETA: 2s - loss: 0.1743 - acc: 0.950011/14 [======================>.......] - ETA: 1s - loss: 0.1654 - acc: 0.954512/14 [========================>.....] - ETA: 1s - loss: 0.1573 - acc: 0.955713/14 [==========================>...] - ETA: 0s - loss: 0.1540 - acc: 0.9567Epoch 00006: val_acc improved from 0.76042 to 0.77083, saving model to /mnt/Data/ltanzi/networksForCam/Fold2_InceptionforCAMA1A2A3-best_model.h5
14/14 [==============================] - 12s - loss: 0.1566 - acc: 0.9574 - val_loss: 0.8191 - val_acc: 0.7708
Epoch 8/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0641 - acc: 0.9688 2/14 [===>..........................] - ETA: 4s - loss: 0.1132 - acc: 0.9688 3/14 [=====>........................] - ETA: 3s - loss: 0.0939 - acc: 0.9792 4/14 [=======>......................] - ETA: 3s - loss: 0.0785 - acc: 0.9844 5/14 [=========>....................] - ETA: 4s - loss: 0.0746 - acc: 0.9875 6/14 [===========>..................] - ETA: 4s - loss: 0.0699 - acc: 0.9844 7/14 [==============>...............] - ETA: 3s - loss: 0.0715 - acc: 0.9866 8/14 [================>.............] - ETA: 3s - loss: 0.0719 - acc: 0.9883 9/14 [==================>...........] - ETA: 2s - loss: 0.0669 - acc: 0.989610/14 [====================>.........] - ETA: 2s - loss: 0.0628 - acc: 0.990611/14 [======================>.......] - ETA: 1s - loss: 0.0607 - acc: 0.991512/14 [========================>.....] - ETA: 1s - loss: 0.0587 - acc: 0.992213/14 [==========================>...] - ETA: 0s - loss: 0.0573 - acc: 0.9928Epoch 00007: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0631 - acc: 0.9910 - val_loss: 1.1477 - val_acc: 0.6875
Epoch 9/150
 1/14 [=>............................] - ETA: 4s - loss: 0.3305 - acc: 0.8750 2/14 [===>..........................] - ETA: 4s - loss: 0.2039 - acc: 0.9062 3/14 [=====>........................] - ETA: 3s - loss: 0.1769 - acc: 0.9271 4/14 [=======>......................] - ETA: 4s - loss: 0.1861 - acc: 0.9375 5/14 [=========>....................] - ETA: 4s - loss: 0.1613 - acc: 0.9437 6/14 [===========>..................] - ETA: 4s - loss: 0.1552 - acc: 0.9479 7/14 [==============>...............] - ETA: 4s - loss: 0.1506 - acc: 0.9509 8/14 [================>.............] - ETA: 3s - loss: 0.1341 - acc: 0.9570 9/14 [==================>...........] - ETA: 2s - loss: 0.1356 - acc: 0.958310/14 [====================>.........] - ETA: 2s - loss: 0.1359 - acc: 0.959411/14 [======================>.......] - ETA: 1s - loss: 0.1258 - acc: 0.963112/14 [========================>.....] - ETA: 1s - loss: 0.1223 - acc: 0.960913/14 [==========================>...] - ETA: 0s - loss: 0.1156 - acc: 0.9639Epoch 00008: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.1098 - acc: 0.9664 - val_loss: 0.7852 - val_acc: 0.7396
Epoch 10/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0211 - acc: 1.0000 2/14 [===>..........................] - ETA: 4s - loss: 0.1077 - acc: 0.9375 3/14 [=====>........................] - ETA: 3s - loss: 0.0875 - acc: 0.9479 4/14 [=======>......................] - ETA: 4s - loss: 0.0883 - acc: 0.9453 5/14 [=========>....................] - ETA: 4s - loss: 0.1099 - acc: 0.9500 6/14 [===========>..................] - ETA: 4s - loss: 0.1044 - acc: 0.9479 7/14 [==============>...............] - ETA: 4s - loss: 0.1004 - acc: 0.9509 8/14 [================>.............] - ETA: 3s - loss: 0.0930 - acc: 0.9570 9/14 [==================>...........] - ETA: 2s - loss: 0.0880 - acc: 0.961810/14 [====================>.........] - ETA: 2s - loss: 0.0805 - acc: 0.965611/14 [======================>.......] - ETA: 1s - loss: 0.0753 - acc: 0.968812/14 [========================>.....] - ETA: 1s - loss: 0.0812 - acc: 0.968813/14 [==========================>...] - ETA: 0s - loss: 0.0792 - acc: 0.9688Epoch 00009: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0806 - acc: 0.9686 - val_loss: 0.6989 - val_acc: 0.7604
Epoch 11/150
 1/14 [=>............................] - ETA: 4s - loss: 0.1035 - acc: 0.9688 2/14 [===>..........................] - ETA: 4s - loss: 0.0847 - acc: 0.9844 3/14 [=====>........................] - ETA: 3s - loss: 0.1305 - acc: 0.9688 4/14 [=======>......................] - ETA: 4s - loss: 0.1461 - acc: 0.9609 5/14 [=========>....................] - ETA: 4s - loss: 0.1303 - acc: 0.9625 6/14 [===========>..................] - ETA: 4s - loss: 0.1151 - acc: 0.9688 7/14 [==============>...............] - ETA: 4s - loss: 0.1041 - acc: 0.9688 8/14 [================>.............] - ETA: 3s - loss: 0.0952 - acc: 0.9727 9/14 [==================>...........] - ETA: 3s - loss: 0.0887 - acc: 0.975710/14 [====================>.........] - ETA: 2s - loss: 0.0802 - acc: 0.978111/14 [======================>.......] - ETA: 1s - loss: 0.0880 - acc: 0.974412/14 [========================>.....] - ETA: 1s - loss: 0.0852 - acc: 0.974013/14 [==========================>...] - ETA: 0s - loss: 0.0823 - acc: 0.9736Epoch 00010: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0781 - acc: 0.9754 - val_loss: 0.7023 - val_acc: 0.7708
Epoch 12/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0757 - acc: 0.9688 2/14 [===>..........................] - ETA: 4s - loss: 0.1009 - acc: 0.9688 3/14 [=====>........................] - ETA: 3s - loss: 0.0716 - acc: 0.9792 4/14 [=======>......................] - ETA: 4s - loss: 0.0632 - acc: 0.9844 5/14 [=========>....................] - ETA: 4s - loss: 0.0561 - acc: 0.9875 6/14 [===========>..................] - ETA: 4s - loss: 0.0513 - acc: 0.9896 7/14 [==============>...............] - ETA: 4s - loss: 0.0632 - acc: 0.9821 8/14 [================>.............] - ETA: 3s - loss: 0.0613 - acc: 0.9805 9/14 [==================>...........] - ETA: 3s - loss: 0.0617 - acc: 0.979210/14 [====================>.........] - ETA: 2s - loss: 0.0653 - acc: 0.975011/14 [======================>.......] - ETA: 1s - loss: 0.0766 - acc: 0.977312/14 [========================>.....] - ETA: 1s - loss: 0.0786 - acc: 0.974013/14 [==========================>...] - ETA: 0s - loss: 0.0743 - acc: 0.9760Epoch 00011: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0710 - acc: 0.9776 - val_loss: 0.6568 - val_acc: 0.7604
Epoch 13/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0532 - acc: 1.0000 2/14 [===>..........................] - ETA: 4s - loss: 0.0571 - acc: 0.9688 3/14 [=====>........................] - ETA: 3s - loss: 0.0576 - acc: 0.9688 4/14 [=======>......................] - ETA: 4s - loss: 0.0677 - acc: 0.9688 5/14 [=========>....................] - ETA: 4s - loss: 0.0601 - acc: 0.9750 6/14 [===========>..................] - ETA: 4s - loss: 0.0542 - acc: 0.9792 7/14 [==============>...............] - ETA: 4s - loss: 0.0583 - acc: 0.9777 8/14 [================>.............] - ETA: 3s - loss: 0.0776 - acc: 0.9688 9/14 [==================>...........] - ETA: 3s - loss: 0.0738 - acc: 0.968810/14 [====================>.........] - ETA: 2s - loss: 0.0679 - acc: 0.971911/14 [======================>.......] - ETA: 2s - loss: 0.0691 - acc: 0.968812/14 [========================>.....] - ETA: 1s - loss: 0.0667 - acc: 0.971413/14 [==========================>...] - ETA: 0s - loss: 0.0659 - acc: 0.9712Epoch 00012: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0682 - acc: 0.9709 - val_loss: 0.8120 - val_acc: 0.7604
Epoch 14/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0087 - acc: 1.0000 2/14 [===>..........................] - ETA: 4s - loss: 0.0196 - acc: 1.0000 3/14 [=====>........................] - ETA: 3s - loss: 0.0215 - acc: 1.0000 4/14 [=======>......................] - ETA: 4s - loss: 0.0503 - acc: 0.9844 5/14 [=========>....................] - ETA: 4s - loss: 0.0633 - acc: 0.9750 6/14 [===========>..................] - ETA: 4s - loss: 0.0578 - acc: 0.9792 7/14 [==============>...............] - ETA: 4s - loss: 0.0546 - acc: 0.9821 8/14 [================>.............] - ETA: 3s - loss: 0.0485 - acc: 0.9844 9/14 [==================>...........] - ETA: 3s - loss: 0.0449 - acc: 0.986110/14 [====================>.........] - ETA: 2s - loss: 0.0641 - acc: 0.981211/14 [======================>.......] - ETA: 2s - loss: 0.0655 - acc: 0.980112/14 [========================>.....] - ETA: 1s - loss: 0.0621 - acc: 0.981813/14 [==========================>...] - ETA: 0s - loss: 0.0579 - acc: 0.9832Epoch 00013: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0559 - acc: 0.9843 - val_loss: 0.7341 - val_acc: 0.7708
Epoch 15/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0173 - acc: 1.0000 2/14 [===>..........................] - ETA: 4s - loss: 0.0285 - acc: 0.9844 3/14 [=====>........................] - ETA: 3s - loss: 0.0304 - acc: 0.9896 4/14 [=======>......................] - ETA: 4s - loss: 0.0322 - acc: 0.9844 5/14 [=========>....................] - ETA: 4s - loss: 0.0319 - acc: 0.9875 6/14 [===========>..................] - ETA: 4s - loss: 0.0408 - acc: 0.9844 7/14 [==============>...............] - ETA: 4s - loss: 0.0795 - acc: 0.9598 8/14 [================>.............] - ETA: 3s - loss: 0.0751 - acc: 0.9648 9/14 [==================>...........] - ETA: 3s - loss: 0.0924 - acc: 0.961810/14 [====================>.........] - ETA: 2s - loss: 0.0916 - acc: 0.959411/14 [======================>.......] - ETA: 2s - loss: 0.0893 - acc: 0.960212/14 [========================>.....] - ETA: 1s - loss: 0.0877 - acc: 0.960913/14 [==========================>...] - ETA: 0s - loss: 0.0825 - acc: 0.9639Epoch 00014: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0772 - acc: 0.9664 - val_loss: 0.9293 - val_acc: 0.7604
Epoch 16/150
 1/14 [=>............................] - ETA: 4s - loss: 0.0138 - acc: 1.0000 2/14 [===>..........................] - ETA: 4s - loss: 0.0208 - acc: 1.0000 3/14 [=====>........................] - ETA: 3s - loss: 0.0339 - acc: 0.9896 4/14 [=======>......................] - ETA: 4s - loss: 0.0495 - acc: 0.9766 5/14 [=========>....................] - ETA: 4s - loss: 0.0511 - acc: 0.9750 6/14 [===========>..................] - ETA: 4s - loss: 0.0506 - acc: 0.9792 7/14 [==============>...............] - ETA: 4s - loss: 0.0488 - acc: 0.9821 8/14 [================>.............] - ETA: 3s - loss: 0.0447 - acc: 0.9844 9/14 [==================>...........] - ETA: 3s - loss: 0.0581 - acc: 0.975710/14 [====================>.........] - ETA: 2s - loss: 0.0542 - acc: 0.978111/14 [======================>.......] - ETA: 2s - loss: 0.0526 - acc: 0.980112/14 [========================>.....] - ETA: 1s - loss: 0.0670 - acc: 0.976613/14 [==========================>...] - ETA: 0s - loss: 0.0629 - acc: 0.9784Epoch 00015: val_acc did not improve
14/14 [==============================] - 12s - loss: 0.0591 - acc: 0.9799 - val_loss: 1.0463 - val_acc: 0.7500
Epoch 17/150
 1/14 [=>............................] - ETA: 1s - loss: 0.0060 - acc: 1.0000 2/14 [===>..........................] - ETA: 2s - loss: 0.0275 - acc: 1.0000 3/14 [=====>........................] - ETA: 3s - loss: 0.0235 - acc: 1.0000 4/14 [=======>......................] - ETA: 2s - loss: 0.0815 - acc: 0.9844 5/14 [=========>....................] - ETA: 3s - loss: 0.0680 - acc: 0.9875 6/14 [===========>..................] - ETA: 3s - loss: 0.0605 - acc: 0.9896 7/14 [==============>...............] - ETA: 3s - loss: 0.0685 - acc: 0.9866 8/14 [================>.............] - ETA: 3s - loss: 0.0675 - acc: 0.9844 9/14 [==================>...........] - ETA: 2s - loss: 0.0626 - acc: 0.986110/14 [====================>.........] - ETA: 2s - loss: 0.0571 - acc: 0.987511/14 [======================>.......] - ETA: 1s - loss: 0.0532 - acc: 0.988612/14 [========================>.....] - ETA: 1s - loss: 0.0546 - acc: 0.987013/14 [==========================>...] - ETA: 0s - loss: 0.0527 - acc: 0.9880Epoch 00016: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0533 - acc: 0.9866 - val_loss: 0.9132 - val_acc: 0.7396
Epoch 18/150
 1/14 [=>............................] - ETA: 4s - loss: 0.1164 - acc: 0.9375 2/14 [===>..........................] - ETA: 2s - loss: 0.0871 - acc: 0.9688 3/14 [=====>........................] - ETA: 3s - loss: 0.0645 - acc: 0.9792 4/14 [=======>......................] - ETA: 2s - loss: 0.0826 - acc: 0.9688 5/14 [=========>....................] - ETA: 3s - loss: 0.0794 - acc: 0.9688 6/14 [===========>..................] - ETA: 3s - loss: 0.0677 - acc: 0.9740 7/14 [==============>...............] - ETA: 3s - loss: 0.0643 - acc: 0.9732 8/14 [================>.............] - ETA: 3s - loss: 0.0622 - acc: 0.9727 9/14 [==================>...........] - ETA: 2s - loss: 0.0578 - acc: 0.975710/14 [====================>.........] - ETA: 2s - loss: 0.0629 - acc: 0.971911/14 [======================>.......] - ETA: 1s - loss: 0.0606 - acc: 0.974412/14 [========================>.....] - ETA: 1s - loss: 0.0569 - acc: 0.976613/14 [==========================>...] - ETA: 0s - loss: 0.0545 - acc: 0.9784Epoch 00017: val_acc did not improve
14/14 [==============================] - 11s - loss: 0.0646 - acc: 0.9754 - val_loss: 0.8882 - val_acc: 0.7708
Epoch 00017: early stopping
EVALUATING MODEL
Test loss: 1.6374922096729279
Test accuracy: 0.6328125
EVALUATING BEST MODEL
Test loss: 1.6432422831350444
Test accuracy: 0.6122448979591837
